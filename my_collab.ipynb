{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f99a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required packages\n",
    "!pip install aiohttp opencv-python pillow pyarrow scikit-learn scipy matplotlib seaborn\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For Fourier analysis\n",
    "from scipy.fft import fft2, fftshift\n",
    "from skimage import filters, transform\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Use notebook-internal class definitions only\n",
    "USE_EXTERNAL_CLASSES = False\n",
    "\n",
    "print(\"All imports successful - using notebook-internal classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningParquetProcessor:\n",
    "    \"\"\"Optimized parquet processing for 4000+ websites\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_parquet_fast(file_path: str, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load parquet with PyArrow for maximum speed\"\"\"\n",
    "        print(f\"Loading parquet: {file_path}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Use PyArrow for fastest loading\n",
    "        import pyarrow.parquet as pq\n",
    "        table = pq.read_table(file_path)\n",
    "        df = table.to_pandas()\n",
    "        \n",
    "        # Sample if requested\n",
    "        if sample_size and len(df) > sample_size:\n",
    "            df = df.sample(n=sample_size, random_state=42)\n",
    "            print(f\" Sampled {sample_size} from {len(table)} total websites\")\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\" Loaded {len(df)} websites in {elapsed:.2f}s\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_website_column(df: pd.DataFrame) -> str:\n",
    "        \"\"\"Auto-detect website column\"\"\"\n",
    "        website_cols = ['website', 'url', 'domain', 'site', 'link']\n",
    "        for col in website_cols:\n",
    "            if col in df.columns:\n",
    "                return col\n",
    "        \n",
    "        # Check for columns containing 'web' or 'url'\n",
    "        for col in df.columns:\n",
    "            if any(term in col.lower() for term in ['web', 'url', 'domain']):\n",
    "                return col\n",
    "        \n",
    "        # Default to first column\n",
    "        return df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc071e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAPILogoExtractor:\n",
    "    \"\"\"Enhanced logo extraction with massive API pool + DNS discovery for 98%+ success rate\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = None\n",
    "        # MEGA-EXPANDED API pool - 49 services across 8 tiers including DNS discovery\n",
    "        self.logo_apis = [\n",
    "            # Tier 1: Premium/Fast APIs (Highest quality, fastest)\n",
    "            {\n",
    "                'name': 'Clearbit',\n",
    "                'url': 'https://logo.clearbit.com/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 1\n",
    "            },\n",
    "            {\n",
    "                'name': 'LogoAPI',\n",
    "                'url': 'https://api.logo.dev/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 1\n",
    "            },\n",
    "            {\n",
    "                'name': 'BrandAPI',\n",
    "                'url': 'https://logo.api.brand.io/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 1\n",
    "            },\n",
    "            {\n",
    "                'name': 'Brandfetch',\n",
    "                'url': 'https://api.brandfetch.io/v2/brands/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 1\n",
    "            },\n",
    "            {\n",
    "                'name': 'LogoGrab',\n",
    "                'url': 'https://api.logograb.com/v1/logo/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 1\n",
    "            },\n",
    "            \n",
    "            # Tier 2: Google & Microsoft Services (Very reliable)\n",
    "            {\n",
    "                'name': 'Google Favicon',\n",
    "                'url': 'https://www.google.com/s2/favicons',\n",
    "                'params': {'domain': '{domain}', 'sz': '128'},\n",
    "                'headers': {},\n",
    "                'timeout': 2,\n",
    "                'tier': 2\n",
    "            },\n",
    "            {\n",
    "                'name': 'Google Favicon HD',\n",
    "                'url': 'https://www.google.com/s2/favicons',\n",
    "                'params': {'domain': '{domain}', 'sz': '256'},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 2\n",
    "            },\n",
    "            {\n",
    "                'name': 'Google Favicon XL',\n",
    "                'url': 'https://www.google.com/s2/favicons',\n",
    "                'params': {'domain': '{domain}', 'sz': '512'},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 2\n",
    "            },\n",
    "            {\n",
    "                'name': 'Microsoft Bing',\n",
    "                'url': 'https://www.bing.com/th',\n",
    "                'params': {'id': 'OIP.{domain}', 'w': '128', 'h': '128', 'c': '7', 'r': '0', 'o': '5'},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 2\n",
    "            },\n",
    "            {\n",
    "                'name': 'DuckDuckGo Favicon',\n",
    "                'url': 'https://icons.duckduckgo.com/ip3/{domain}.ico',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 2\n",
    "            },\n",
    "            \n",
    "            # Tier 3: Alternative Favicon Services & CDNs\n",
    "            {\n",
    "                'name': 'Favicon.io',\n",
    "                'url': 'https://favicons.githubusercontent.com/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'Icons8',\n",
    "                'url': 'https://img.icons8.com/color/128/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'Favicon Kit',\n",
    "                'url': 'https://www.faviconkit.com/{domain}/128',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'Favicon Grabber',\n",
    "                'url': 'https://favicongrabber.com/api/grab/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'GetFavicon',\n",
    "                'url': 'https://getfavicon.appspot.com/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'Besticon',\n",
    "                'url': 'https://besticon-demo.herokuapp.com/icon',\n",
    "                'params': {'url': 'https://{domain}', 'size': '128'},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 3\n",
    "            },\n",
    "            {\n",
    "                'name': 'Iconscout',\n",
    "                'url': 'https://cdn.iconscout.com/icon/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 3\n",
    "            },\n",
    "            \n",
    "            # Tier 4: Social Media & Directory APIs\n",
    "            {\n",
    "                'name': 'Wikipedia',\n",
    "                'url': 'https://en.wikipedia.org/api/rest_v1/page/summary/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 5,\n",
    "                'tier': 4\n",
    "            },\n",
    "            {\n",
    "                'name': 'Wikidata',\n",
    "                'url': 'https://www.wikidata.org/w/api.php',\n",
    "                'params': {'action': 'wbsearchentities', 'search': '{domain}', 'format': 'json', 'language': 'en'},\n",
    "                'headers': {},\n",
    "                'timeout': 5,\n",
    "                'tier': 4\n",
    "            },\n",
    "            {\n",
    "                'name': 'Company Logo DB',\n",
    "                'url': 'https://logo.clearbitjs.com/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 4\n",
    "            },\n",
    "            {\n",
    "                'name': 'LogoTyp',\n",
    "                'url': 'https://logotyp.us/logo/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 4,\n",
    "                'tier': 4\n",
    "            },\n",
    "            {\n",
    "                'name': 'OpenCorporates',\n",
    "                'url': 'https://api.opencorporates.com/companies/search',\n",
    "                'params': {'q': '{domain}', 'format': 'json'},\n",
    "                'headers': {},\n",
    "                'timeout': 5,\n",
    "                'tier': 4\n",
    "            },\n",
    "            \n",
    "            # Tier 5: Web Archive & Metadata\n",
    "            {\n",
    "                'name': 'Internet Archive',\n",
    "                'url': 'https://web.archive.org/cdx/search/cdx',\n",
    "                'params': {'url': '{domain}/favicon.ico', 'output': 'json', 'limit': '1'},\n",
    "                'headers': {},\n",
    "                'timeout': 6,\n",
    "                'tier': 5\n",
    "            },\n",
    "            {\n",
    "                'name': 'Archive Today',\n",
    "                'url': 'https://archive.today/timemap/json/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 6,\n",
    "                'tier': 5\n",
    "            },\n",
    "            {\n",
    "                'name': 'Logo Garden',\n",
    "                'url': 'https://www.logoground.com/api/logo/{domain}',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 5,\n",
    "                'tier': 5\n",
    "            },\n",
    "            \n",
    "            # Tier 6: Direct Website Scraping (High success fallback)\n",
    "            {\n",
    "                'name': 'Direct Favicon',\n",
    "                'url': 'https://{domain}/favicon.ico',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Apple Touch Icon',\n",
    "                'url': 'https://{domain}/apple-touch-icon.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Apple Touch Icon 152',\n",
    "                'url': 'https://{domain}/apple-touch-icon-152x152.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Apple Touch Icon 180',\n",
    "                'url': 'https://{domain}/apple-touch-icon-180x180.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Android Chrome 192',\n",
    "                'url': 'https://{domain}/android-chrome-192x192.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Android Chrome 512',\n",
    "                'url': 'https://{domain}/android-chrome-512x512.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Site Logo PNG',\n",
    "                'url': 'https://{domain}/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Site Logo SVG',\n",
    "                'url': 'https://{domain}/logo.svg',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Assets Logo',\n",
    "                'url': 'https://{domain}/assets/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Images Logo',\n",
    "                'url': 'https://{domain}/images/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Static Logo',\n",
    "                'url': 'https://{domain}/static/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            {\n",
    "                'name': 'Brand Logo',\n",
    "                'url': 'https://{domain}/brand/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 6\n",
    "            },\n",
    "            \n",
    "            # Tier 7: Alternative domains and variations  \n",
    "            {\n",
    "                'name': 'WWW Favicon',\n",
    "                'url': 'https://www.{domain}/favicon.ico',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 7\n",
    "            },\n",
    "            {\n",
    "                'name': 'WWW Logo',\n",
    "                'url': 'https://www.{domain}/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 7\n",
    "            },\n",
    "            {\n",
    "                'name': 'CDN Logo',\n",
    "                'url': 'https://cdn.{domain}/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 7\n",
    "            },\n",
    "            {\n",
    "                'name': 'Media Logo',\n",
    "                'url': 'https://media.{domain}/logo.png',\n",
    "                'params': {},\n",
    "                'headers': {},\n",
    "                'timeout': 3,\n",
    "                'tier': 7\n",
    "            },\n",
    "            \n",
    "            # Tier 8: DNS & WHOIS-Based Logo Discovery \n",
    "            {\n",
    "                'name': 'DNS-over-HTTPS Logo TXT',\n",
    "                'url': 'https://cloudflare-dns.com/dns-query',\n",
    "                'params': {'name': 'logo.{domain}', 'type': 'TXT', 'ct': 'application/dns-json'},\n",
    "                'headers': {'accept': 'application/dns-json'},\n",
    "                'timeout': 5,\n",
    "                'tier': 8,\n",
    "                'dns_query': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'DNS-over-HTTPS Brand TXT',\n",
    "                'url': 'https://cloudflare-dns.com/dns-query',\n",
    "                'params': {'name': 'brand.{domain}', 'type': 'TXT', 'ct': 'application/dns-json'},\n",
    "                'headers': {'accept': 'application/dns-json'},\n",
    "                'timeout': 5,\n",
    "                'tier': 8,\n",
    "                'dns_query': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'DNS-over-HTTPS Assets TXT',\n",
    "                'url': 'https://cloudflare-dns.com/dns-query',\n",
    "                'params': {'name': 'assets.{domain}', 'type': 'TXT', 'ct': 'application/dns-json'},\n",
    "                'headers': {'accept': 'application/dns-json'},\n",
    "                'timeout': 5,\n",
    "                'tier': 8,\n",
    "                'dns_query': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'Google DNS Logo TXT',\n",
    "                'url': 'https://dns.google/resolve',\n",
    "                'params': {'name': 'logo.{domain}', 'type': 'TXT'},\n",
    "                'headers': {},\n",
    "                'timeout': 5,\n",
    "                'tier': 8,\n",
    "                'dns_query': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'WHOIS Brand API',\n",
    "                'url': 'https://www.whoisxmlapi.com/whoisserver/WhoisService',\n",
    "                'params': {'domainName': '{domain}', 'outputFormat': 'JSON', 'apiKey': 'demo'},\n",
    "                'headers': {},\n",
    "                'timeout': 6,\n",
    "                'tier': 8,\n",
    "                'whois_query': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'Domain Tools Logo',\n",
    "                'url': 'https://api.domaintools.com/v1/{domain}/hosting-history',\n",
    "                'params': {'format': 'json'},\n",
    "                'headers': {},\n",
    "                'timeout': 6,\n",
    "                'tier': 8,\n",
    "                'domain_meta': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'SecurityTrails DNS',\n",
    "                'url': 'https://api.securitytrails.com/v1/domain/{domain}/subdomains',\n",
    "                'params': {},\n",
    "                'headers': {'APIKEY': 'demo'},\n",
    "                'timeout': 6,\n",
    "                'tier': 8,\n",
    "                'subdomain_scan': True\n",
    "            },\n",
    "            {\n",
    "                'name': 'VirusTotal Domain',\n",
    "                'url': 'https://www.virustotal.com/vtapi/v2/domain/report',\n",
    "                'params': {'domain': '{domain}', 'apikey': 'demo'},\n",
    "                'headers': {},\n",
    "                'timeout': 6,\n",
    "                'tier': 8,\n",
    "                'domain_intel': True\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        timeout = aiohttp.ClientTimeout(total=20)  # Increased timeout for more APIs\n",
    "        connector = aiohttp.TCPConnector(limit=400, limit_per_host=150)  # Higher limits\n",
    "        self.session = aiohttp.ClientSession(\n",
    "            timeout=timeout,\n",
    "            connector=connector,\n",
    "            headers={'User-Agent': 'LogoMatcher/3.0 Ultra-Enhanced'}\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "    \n",
    "    def clean_domain(self, website: str) -> str:\n",
    "        \"\"\"Extract clean domain from website URL\"\"\"\n",
    "        if website.startswith(('http://', 'https://')):\n",
    "            from urllib.parse import urlparse\n",
    "            parsed = urlparse(website)\n",
    "            domain = parsed.netloc\n",
    "            # Remove www. prefix for cleaner API calls\n",
    "            if domain.startswith('www.'):\n",
    "                domain = domain[4:]\n",
    "            return domain\n",
    "        return website\n",
    "    \n",
    "    async def try_api_service(self, api_config: dict, domain: str) -> Optional[Dict]:\n",
    "        \"\"\"Try a single API service for logo\"\"\"\n",
    "        try:\n",
    "            # Format URL\n",
    "            if '{domain}' in api_config['url']:\n",
    "                url = api_config['url'].format(domain=domain)\n",
    "            else:\n",
    "                url = api_config['url']\n",
    "            \n",
    "            # Format params\n",
    "            params = {}\n",
    "            for key, value in api_config.get('params', {}).items():\n",
    "                if '{domain}' in str(value):\n",
    "                    params[key] = value.format(domain=domain)\n",
    "                else:\n",
    "                    params[key] = value\n",
    "            \n",
    "            # Make request\n",
    "            timeout = aiohttp.ClientTimeout(total=api_config['timeout'])\n",
    "            async with self.session.get(\n",
    "                url, \n",
    "                params=params,\n",
    "                headers=api_config.get('headers', {}),\n",
    "                timeout=timeout,\n",
    "                allow_redirects=True  # Follow redirects for better coverage\n",
    "            ) as response:\n",
    "                \n",
    "                if response.status == 200:\n",
    "                    content_type = response.headers.get('content-type', '')\n",
    "                    \n",
    "                    # Handle different response types\n",
    "                    if 'image' in content_type:\n",
    "                        content = await response.read()\n",
    "                        if len(content) > 200:  # Lowered threshold for more logos\n",
    "                            return {\n",
    "                                'data': content,\n",
    "                                'url': str(response.url),\n",
    "                                'content_type': content_type,\n",
    "                                'size': len(content)\n",
    "                            }\n",
    "                    \n",
    "                    elif 'json' in content_type or api_config.get('dns_query') or api_config.get('whois_query'):\n",
    "                        # Handle JSON responses (Wikipedia, Wikidata, DNS, WHOIS, etc.)\n",
    "                        json_data = await response.json()\n",
    "                        logo_url = self.extract_logo_from_json(json_data, api_config['name'])\n",
    "                        if logo_url:\n",
    "                            # Download the actual logo\n",
    "                            logo_result = await self.download_logo_from_url(logo_url)\n",
    "                            if logo_result:\n",
    "                                return logo_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Silent fail for speed - but we can uncomment for debugging\n",
    "            # print(f\"API {api_config['name']} failed for {domain}: {e}\")\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_logo_from_json(self, json_data: dict, api_name: str) -> Optional[str]:\n",
    "        \"\"\"Extract logo URL from JSON API responses\"\"\"\n",
    "        try:\n",
    "            if api_name == 'Wikipedia':\n",
    "                if 'thumbnail' in json_data and 'source' in json_data['thumbnail']:\n",
    "                    return json_data['thumbnail']['source']\n",
    "                elif 'originalimage' in json_data and 'source' in json_data['originalimage']:\n",
    "                    return json_data['originalimage']['source']\n",
    "            \n",
    "            elif api_name == 'Wikidata':\n",
    "                if 'search' in json_data and json_data['search']:\n",
    "                    for item in json_data['search']:\n",
    "                        if 'display' in item and 'label' in item['display']:\n",
    "                            # This would need additional API calls to get the actual logo\n",
    "                            pass\n",
    "            \n",
    "            elif api_name == 'Favicon Grabber':\n",
    "                if 'icons' in json_data and json_data['icons']:\n",
    "                    # Return the largest icon\n",
    "                    largest_icon = max(json_data['icons'], key=lambda x: x.get('sizes', '0x0').split('x')[0])\n",
    "                    return largest_icon.get('src')\n",
    "            \n",
    "            elif api_name == 'OpenCorporates':\n",
    "                if 'results' in json_data and json_data['results']:\n",
    "                    for company in json_data['results']['companies']:\n",
    "                        if 'company' in company and 'registry_url' in company['company']:\n",
    "                            # Additional processing could extract logos from company pages\n",
    "                            pass\n",
    "            \n",
    "            # DNS-based Logo Discovery\n",
    "            elif 'DNS Logo TXT' in api_name or 'DNS Brand TXT' in api_name or 'DNS Assets TXT' in api_name:\n",
    "                # Parse DNS TXT records for logo URLs\n",
    "                if 'Answer' in json_data:\n",
    "                    for record in json_data['Answer']:\n",
    "                        if record.get('type') == 16:  # TXT record\n",
    "                            txt_data = record.get('data', '')\n",
    "                            # Look for logo URLs in TXT records\n",
    "                            logo_url = self.extract_logo_url_from_txt(txt_data)\n",
    "                            if logo_url:\n",
    "                                return logo_url\n",
    "                elif 'answer' in json_data:  # Google DNS format\n",
    "                    for record in json_data['answer']:\n",
    "                        if record.get('type') == 16:\n",
    "                            txt_data = record.get('data', '')\n",
    "                            logo_url = self.extract_logo_url_from_txt(txt_data)\n",
    "                            if logo_url:\n",
    "                                return logo_url\n",
    "            \n",
    "            elif api_name == 'WHOIS Brand API':\n",
    "                # Extract logo info from WHOIS data\n",
    "                whois_data = json_data.get('WhoisRecord', {})\n",
    "                registrant = whois_data.get('registrant', {})\n",
    "                if 'organization' in registrant:\n",
    "                    # Could cross-reference with other APIs\n",
    "                    pass\n",
    "            \n",
    "            elif api_name == 'SecurityTrails DNS':\n",
    "                # Look for logo-related subdomains\n",
    "                if 'subdomains' in json_data:\n",
    "                    for subdomain in json_data['subdomains']:\n",
    "                        if any(keyword in subdomain.lower() for keyword in ['logo', 'brand', 'assets', 'cdn', 'static']):\n",
    "                            # Try common logo paths on these subdomains\n",
    "                            potential_url = f\"https://{subdomain}.{json_data.get('domain', '')}/logo.png\"\n",
    "                            return potential_url\n",
    "                        \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_logo_url_from_txt(self, txt_data: str) -> Optional[str]:\n",
    "        \"\"\"Extract logo URL from DNS TXT record data\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Common TXT record patterns for logo URLs\n",
    "        patterns = [\n",
    "            r'logo[_-]?url[=:]\\s*([^\\s\"\\']+)',  # logo_url=https://...\n",
    "            r'brand[_-]?logo[=:]\\s*([^\\s\"\\']+)',  # brand_logo=https://...\n",
    "            r'icon[_-]?url[=:]\\s*([^\\s\"\\']+)',   # icon_url=https://...\n",
    "            r'(https?://[^\\s\"\\']+\\.(?:png|jpg|jpeg|svg|gif|webp))',  # Direct URL patterns\n",
    "            r'assets[=:]\\s*([^\\s\"\\']+)',  # assets=https://cdn.../logo.png\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, txt_data, re.IGNORECASE)\n",
    "            if match:\n",
    "                url = match.group(1)\n",
    "                if url.startswith(('http://', 'https://')):\n",
    "                    return url\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    async def download_logo_from_url(self, logo_url: str) -> Optional[Dict]:\n",
    "        \"\"\"Download logo from extracted URL\"\"\"\n",
    "        try:\n",
    "            timeout = aiohttp.ClientTimeout(total=5)\n",
    "            async with self.session.get(logo_url, timeout=timeout, allow_redirects=True) as response:\n",
    "                if response.status == 200:\n",
    "                    content_type = response.headers.get('content-type', '')\n",
    "                    if 'image' in content_type:\n",
    "                        content = await response.read()\n",
    "                        if len(content) > 200:\n",
    "                            return {\n",
    "                                'data': content,\n",
    "                                'url': logo_url,\n",
    "                                'content_type': content_type,\n",
    "                                'size': len(content)\n",
    "                            }\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    async def extract_logo_tiered(self, website: str, max_tier: int = 8) -> Dict:\n",
    "        \"\"\"Extract logo using expanded tiered API approach for 97%+ success\"\"\"\n",
    "        domain = self.clean_domain(website)\n",
    "        \n",
    "        result = {\n",
    "            'website': website,\n",
    "            'domain': domain,\n",
    "            'logo_found': False,\n",
    "            'logo_url': None,\n",
    "            'logo_data': None,\n",
    "            'method': 'ultra_enhanced_api',\n",
    "            'api_service': None,\n",
    "            'tier_used': None,\n",
    "            'attempts': 0,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "        # Try APIs by tier for maximum efficiency\n",
    "        for tier in range(1, max_tier + 1):\n",
    "            tier_apis = [api for api in self.logo_apis if api.get('tier') == tier]\n",
    "            \n",
    "            # Try all APIs in current tier concurrently\n",
    "            if tier_apis:\n",
    "                tasks = [self.try_api_service(api_config, domain) for api_config in tier_apis]\n",
    "                tier_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "                \n",
    "                # Check for success in this tier\n",
    "                for i, logo_result in enumerate(tier_results):\n",
    "                    if isinstance(logo_result, dict) and logo_result:\n",
    "                        result.update({\n",
    "                            'logo_found': True,\n",
    "                            'logo_url': logo_result['url'],\n",
    "                            'logo_data': logo_result['data'],\n",
    "                            'method': 'ultra_enhanced_api',\n",
    "                            'api_service': tier_apis[i]['name'],\n",
    "                            'tier_used': tier,\n",
    "                            'attempts': result['attempts'] + len(tier_apis)\n",
    "                        })\n",
    "                        return result\n",
    "                \n",
    "                result['attempts'] += len(tier_apis)\n",
    "                \n",
    "                # Brief pause between tiers (less for early tiers)\n",
    "                if tier <= 4:\n",
    "                    await asyncio.sleep(0.1)\n",
    "                else:\n",
    "                    await asyncio.sleep(0.2)  # Longer pause for slower tiers\n",
    "        \n",
    "        result['error'] = f'All {result[\"attempts\"]} APIs failed'\n",
    "        return result\n",
    "    \n",
    "    async def extract_logo_exhaustive_retry(self, website: str, max_tier: int = 7) -> Dict:\n",
    "        \"\"\"\n",
    "        EXHAUSTIVE RETRY: Try failed websites against ALL APIs in random order\n",
    "        This maximizes success rate by trying different API combinations\n",
    "        \"\"\"\n",
    "        domain = self.clean_domain(website)\n",
    "        \n",
    "        result = {\n",
    "            'website': website,\n",
    "            'domain': domain,\n",
    "            'logo_found': False,\n",
    "            'logo_url': None,\n",
    "            'logo_data': None,\n",
    "            'method': 'exhaustive_retry',\n",
    "            'api_service': None,\n",
    "            'tier_used': None,\n",
    "            'attempts': 0,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "        # Get ALL APIs up to max_tier and shuffle them for random order\n",
    "        import random\n",
    "        all_apis = [api for api in self.logo_apis if api.get('tier', 1) <= max_tier]\n",
    "        random.shuffle(all_apis)  # Random order for better coverage\n",
    "        \n",
    "        print(f\"Exhaustive retry for {domain}: trying {len(all_apis)} APIs\")\n",
    "        \n",
    "        # Try APIs in smaller chunks to be respectful\n",
    "        chunk_size = 5\n",
    "        for i in range(0, len(all_apis), chunk_size):\n",
    "            chunk = all_apis[i:i + chunk_size]\n",
    "            \n",
    "            # Try chunk concurrently\n",
    "            tasks = [self.try_api_service(api_config, domain) for api_config in chunk]\n",
    "            chunk_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "            # Check for success in this chunk\n",
    "            for j, logo_result in enumerate(chunk_results):\n",
    "                if isinstance(logo_result, dict) and logo_result:\n",
    "                    result.update({\n",
    "                        'logo_found': True,\n",
    "                        'logo_url': logo_result['url'],\n",
    "                        'logo_data': logo_result['data'],\n",
    "                        'method': 'exhaustive_retry',\n",
    "                        'api_service': chunk[j]['name'],\n",
    "                        'tier_used': chunk[j]['tier'],\n",
    "                        'attempts': result['attempts'] + len(chunk)\n",
    "                    })\n",
    "                    print(f\"Retry success for {domain}: {chunk[j]['name']}\")\n",
    "                    return result\n",
    "            \n",
    "            result['attempts'] += len(chunk)\n",
    "            \n",
    "            # Brief pause between chunks\n",
    "            await asyncio.sleep(0.1)\n",
    "        \n",
    "        result['error'] = f'Exhaustive retry failed: {result[\"attempts\"]} APIs tried'\n",
    "        return result\n",
    "    \n",
    "    async def batch_extract_logos_enhanced(self, websites: List[str], max_tier: int = 8) -> List[Dict]:\n",
    "        print(f\"ULTRA-ENHANCED API extraction: {len(websites)} websites\")\n",
    "        print(f\"Using {len([api for api in self.logo_apis if api.get('tier', 1) <= max_tier])} APIs across {max_tier} tiers\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process websites in optimal batch size\n",
    "        batch_size = 30  # Smaller batches for more APIs\n",
    "        all_results = []\n",
    "        \n",
    "        for i in range(0, len(websites), batch_size):\n",
    "            batch = websites[i:i + batch_size]\n",
    "            batch_num = i//batch_size + 1\n",
    "            total_batches = (len(websites)-1)//batch_size + 1\n",
    "            \n",
    "            print(f\"   Batch {batch_num}/{total_batches}: {len(batch)} websites\")\n",
    "            \n",
    "            # Process batch concurrently\n",
    "            tasks = [self.extract_logo_tiered(website, max_tier) for website in batch]\n",
    "            batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "            # Filter results\n",
    "            for j, result in enumerate(batch_results):\n",
    "                if isinstance(result, dict):\n",
    "                    all_results.append(result)\n",
    "                else:\n",
    "                    all_results.append({\n",
    "                        'website': batch[j],\n",
    "                        'logo_found': False,\n",
    "                        'error': f'Exception: {type(result).__name__}'\n",
    "                    })\n",
    "            \n",
    "            # Show batch progress\n",
    "            batch_successful = sum(1 for r in batch_results if isinstance(r, dict) and r.get('logo_found', False))\n",
    "            print(f\"Batch success: {batch_successful}/{len(batch)} ({batch_successful/len(batch)*100:.1f}%)\")\n",
    "            \n",
    "            # Brief pause between batches\n",
    "            await asyncio.sleep(0.3)\n",
    "        \n",
    "        # EXHAUSTIVE RETRY for failed websites\n",
    "        failed_results = [r for r in all_results if not r['logo_found']]\n",
    "        if failed_results and len(failed_results) <= 50:  # Only retry if not too many failures\n",
    "            print(f\"\\nEXHAUSTIVE RETRY PHASE\")\n",
    "            print(f\"Retrying {len(failed_results)} failed websites with ALL APIs...\")\n",
    "            \n",
    "            retry_websites = [r['website'] for r in failed_results]\n",
    "            retry_tasks = [self.extract_logo_exhaustive_retry(website, max_tier) for website in retry_websites]\n",
    "            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)\n",
    "            \n",
    "            # Update original results with retry successes\n",
    "            retry_successes = 0\n",
    "            for i, retry_result in enumerate(retry_results):\n",
    "                if isinstance(retry_result, dict) and retry_result.get('logo_found', False):\n",
    "                    # Find and update the original failed result\n",
    "                    original_website = retry_websites[i]\n",
    "                    for j, original_result in enumerate(all_results):\n",
    "                        if original_result['website'] == original_website and not original_result['logo_found']:\n",
    "                            all_results[j] = retry_result\n",
    "                            retry_successes += 1\n",
    "                            break\n",
    "            \n",
    "            if retry_successes > 0:\n",
    "                print(f\"Exhaustive retry recovered {retry_successes} additional logos!\")\n",
    "            else:\n",
    "                print(\"No additional logos found in retry phase\")\n",
    "        \n",
    "        elif len(failed_results) > 50:\n",
    "            print(f\"\\nSkipping exhaustive retry: {len(failed_results)} failures (too many)\")\n",
    "            print(\"Consider increasing max_tier or checking network connectivity\")\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        successful = sum(1 for r in all_results if r['logo_found'])\n",
    "        success_rate = successful / len(websites) * 100\n",
    "        \n",
    "        print(f\"ULTRA-ENHANCED results: {successful}/{len(websites)} in {elapsed:.1f}s\")\n",
    "        print(f\"SUCCESS RATE: {success_rate:.1f}%\")\n",
    "        print(f\"Speed: {len(websites)/elapsed:.1f} websites/second\")\n",
    "        \n",
    "        # Show comprehensive breakdown\n",
    "        tier_breakdown = defaultdict(int)\n",
    "        api_breakdown = defaultdict(int)\n",
    "        \n",
    "        for result in all_results:\n",
    "            if result['logo_found']:\n",
    "                tier = result.get('tier_used', 'unknown')\n",
    "                service = result.get('api_service', 'unknown')\n",
    "                tier_breakdown[f\"Tier {tier}\"] += 1\n",
    "                api_breakdown[service] += 1\n",
    "        \n",
    "        print(\"\\nPERFORMANCE BREAKDOWN:\")\n",
    "        print(\"By Tier:\")\n",
    "        for tier, count in sorted(tier_breakdown.items()):\n",
    "            percentage = count / successful * 100 if successful > 0 else 0\n",
    "            print(f\"   - {tier}: {count} logos ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"Top API Services:\")\n",
    "        for service, count in sorted(api_breakdown.items(), key=lambda x: x[1], reverse=True)[:8]:\n",
    "            percentage = count / successful * 100 if successful > 0 else 0\n",
    "            print(f\"   - {service}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Success rate assessment\n",
    "        if success_rate >= 97:\n",
    "            print(f\"EXCELLENT! {success_rate:.1f}% SUCCESS RATE ACHIEVED!\")\n",
    "        elif success_rate >= 95:\n",
    "            print(f\"\\nVERY GOOD! {success_rate:.1f}% success rate\")\n",
    "            print(\"Close to 97% target - consider adding tier 8 for remaining sites\")\n",
    "        elif success_rate >= 90:\n",
    "            print(f\"\\nGOOD! {success_rate:.1f}% success rate\")\n",
    "            print(\"To reach 97%+: increase max_tier or add more API services\")\n",
    "        else:\n",
    "            print(f\"\\n{success_rate:.1f}% success rate - needs improvement\")\n",
    "            print(\"Try max_tier=7 and check API service availability\")\n",
    "        \n",
    "        return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnionFind:\n",
    "    \"\"\"Union-Find data structure for clustering\"\"\"\n",
    "    \n",
    "    def __init__(self, elements):\n",
    "        self.parent = {elem: elem for elem in elements}\n",
    "        self.rank = {elem: 0 for elem in elements}\n",
    "    \n",
    "    def find(self, x):\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])  # Path compression\n",
    "        return self.parent[x]\n",
    "    \n",
    "    def union(self, x, y):\n",
    "        px, py = self.find(x), self.find(y)\n",
    "        if px == py:\n",
    "            return\n",
    "        \n",
    "        # Union by rank\n",
    "        if self.rank[px] < self.rank[py]:\n",
    "            px, py = py, px\n",
    "        self.parent[py] = px\n",
    "        if self.rank[px] == self.rank[py]:\n",
    "            self.rank[px] += 1\n",
    "    \n",
    "    def get_clusters(self):\n",
    "        clusters = defaultdict(list)\n",
    "        for elem in self.parent:\n",
    "            root = self.find(elem)\n",
    "            clusters[root].append(elem)\n",
    "        return [cluster for cluster in clusters.values() if len(cluster) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc82de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.fft import fft2, fftshift\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage.filters import gabor\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.special import factorial\n",
    "import cmath\n",
    "import colorsys\n",
    "\n",
    "class FourierLogoAnalyzer:\n",
    "    \"\"\"\n",
    "    Enhanced logo analyzer with ALL 2025 research features:\n",
    "    - Traditional: pHash, FFT, Fourier-Mellin, SIFT, ORB\n",
    "    - Advanced: Hu/Zernike moments, LBP, GLCM, Gabor, saliency-weighted hashing\n",
    "    - Color-aware: Per-channel Fourier-Mellin, enhanced color features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.similarity_threshold_phash = 6  # Hamming distance\n",
    "        self.similarity_threshold_fft = 0.985  # Cosine similarity\n",
    "        self.similarity_threshold_fmt = 0.995  # Fourier-Mellin\n",
    "        \n",
    "        # Advanced feature parameters\n",
    "        self.zernike_max_order = 8\n",
    "        self.lbp_radius = 3\n",
    "        self.lbp_n_points = 8 * self.lbp_radius\n",
    "        self.gabor_frequencies = [0.1, 0.3, 0.5]\n",
    "        self.gabor_angles = [0, 45, 90, 135]\n",
    "    \n",
    "    def compute_phash(self, img: np.ndarray) -> str:\n",
    "        \"\"\"Compute perceptual hash using DCT (Fourier cousin)\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Resize to 32x32 for DCT\n",
    "        resized = cv2.resize(gray, (32, 32))\n",
    "        \n",
    "        # Compute DCT (like 2D Fourier but with cosines)\n",
    "        dct = cv2.dct(np.float32(resized))\n",
    "        \n",
    "        # Take top-left 8x8 (low frequencies)\n",
    "        dct_low = dct[0:8, 0:8]\n",
    "        \n",
    "        # Compare with median to create binary hash\n",
    "        median = np.median(dct_low)\n",
    "        binary = dct_low > median\n",
    "        \n",
    "        # Convert to hex string\n",
    "        hash_str = ''.join(['1' if b else '0' for b in binary.flatten()])\n",
    "        return hash_str\n",
    "    \n",
    "    def hamming_distance(self, hash1: str, hash2: str) -> int:\n",
    "        \"\"\"Calculate Hamming distance between two hashes\"\"\"\n",
    "        return sum(c1 != c2 for c1, c2 in zip(hash1, hash2))\n",
    "    \n",
    "    def color_distance(self, a, b):\n",
    "        \"\"\"Compute Euclidean distance between color vectors\"\"\"\n",
    "        return np.linalg.norm(np.array(a) - np.array(b))\n",
    "    \n",
    "    def compute_fft_features(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute FFT low-frequency features for global shape\"\"\"\n",
    "        # Convert to grayscale and normalize\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = gray.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Resize to square and standard size\n",
    "        size = 128\n",
    "        resized = cv2.resize(gray, (size, size))\n",
    "        \n",
    "        # Compute 2D FFT\n",
    "        fft = fft2(resized)\n",
    "        fft_shifted = fftshift(fft)\n",
    "        \n",
    "        # Take magnitude and apply log\n",
    "        magnitude = np.abs(fft_shifted)\n",
    "        log_magnitude = np.log(magnitude + 1e-8)\n",
    "        \n",
    "        # Extract central low-frequency block (32x32)\n",
    "        center = size // 2\n",
    "        crop_size = 16\n",
    "        low_freq = log_magnitude[\n",
    "            center-crop_size:center+crop_size,\n",
    "            center-crop_size:center+crop_size\n",
    "        ]\n",
    "        \n",
    "        # Flatten and normalize\n",
    "        features = low_freq.flatten()\n",
    "        features = features / (np.linalg.norm(features) + 1e-8)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def compute_fourier_mellin_signature(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Fourier-Mellin theta signature for rotation/scale invariance\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = gray.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Resize to square\n",
    "        size = 128\n",
    "        resized = cv2.resize(gray, (size, size))\n",
    "        \n",
    "        # Compute FFT and get magnitude\n",
    "        fft = fft2(resized)\n",
    "        fft_shifted = fftshift(fft)\n",
    "        magnitude = np.abs(fft_shifted)\n",
    "        \n",
    "        # Convert to log-polar coordinates\n",
    "        center = size // 2\n",
    "        theta_samples = 64\n",
    "        radius_samples = 32\n",
    "        \n",
    "        # Create theta signature by averaging over radius\n",
    "        theta_signature = np.zeros(theta_samples)\n",
    "        \n",
    "        for i, theta in enumerate(np.linspace(0, 2*np.pi, theta_samples, endpoint=False)):\n",
    "            # Sample along radial lines\n",
    "            radial_sum = 0\n",
    "            for r in np.linspace(1, center-1, radius_samples):\n",
    "                x = int(center + r * np.cos(theta))\n",
    "                y = int(center + r * np.sin(theta))\n",
    "                if 0 <= x < size and 0 <= y < size:\n",
    "                    radial_sum += magnitude[y, x]\n",
    "            theta_signature[i] = radial_sum\n",
    "        \n",
    "        # Normalize\n",
    "        theta_signature = theta_signature / (np.linalg.norm(theta_signature) + 1e-8)\n",
    "        \n",
    "        return theta_signature\n",
    "    \n",
    "    def compute_color_aware_fmt(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Color-aware Fourier-Mellin preserving color relationships\"\"\"\n",
    "        try:\n",
    "            if len(img.shape) != 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            img_resized = cv2.resize(img, (128, 128))\n",
    "            channel_signatures = []\n",
    "            \n",
    "            for c in range(3):  # B, G, R channels\n",
    "                channel = img_resized[:, :, c].astype(np.float32) / 255.0\n",
    "                \n",
    "                # Apply 2D FFT\n",
    "                fft = np.fft.fft2(channel)\n",
    "                fft_shift = np.fft.fftshift(fft)\n",
    "                magnitude = np.abs(fft_shift)\n",
    "                \n",
    "                # Convert to log-polar coordinates\n",
    "                center_x, center_y = magnitude.shape[1] // 2, magnitude.shape[0] // 2\n",
    "                \n",
    "                # Create log-polar sampling grid\n",
    "                signature_size = 32\n",
    "                theta_samples = np.linspace(0, 2 * np.pi, signature_size, endpoint=False)\n",
    "                rho_max = min(center_x, center_y) - 1\n",
    "                rho_samples = np.logspace(0, np.log10(rho_max), signature_size // 2)\n",
    "                \n",
    "                signature = []\n",
    "                for rho in rho_samples:\n",
    "                    theta_signature = []\n",
    "                    for theta in theta_samples:\n",
    "                        x = int(center_x + rho * np.cos(theta))\n",
    "                        y = int(center_y + rho * np.sin(theta))\n",
    "                        \n",
    "                        if 0 <= x < magnitude.shape[1] and 0 <= y < magnitude.shape[0]:\n",
    "                            theta_signature.append(magnitude[y, x])\n",
    "                        else:\n",
    "                            theta_signature.append(0.0)\n",
    "                    \n",
    "                    signature.append(np.max(theta_signature))\n",
    "                \n",
    "                channel_signatures.append(signature)\n",
    "            \n",
    "            return np.concatenate(channel_signatures).astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return np.zeros(48, dtype=np.float32)  # 3 channels * 16 features each\n",
    "    \n",
    "    def compute_saliency_weighted_fft(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Saliency-weighted FFT emphasizing perceptually significant regions\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale if needed\n",
    "            if len(img.shape) == 3:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = img.copy()\n",
    "            \n",
    "            # Compute frequency-tuned saliency map\n",
    "            gaussian_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "            mean_val = np.mean(gaussian_blur)\n",
    "            saliency = np.abs(gray.astype(np.float32) - mean_val)\n",
    "            \n",
    "            # Enhance with edge information\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            edge_weight = edges.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Combine intensity saliency with edge saliency\n",
    "            saliency = 0.7 * saliency + 0.3 * edge_weight * 255\n",
    "            saliency = saliency / (np.max(saliency) + 1e-8)\n",
    "            saliency = cv2.GaussianBlur(saliency, (3, 3), 0)\n",
    "            \n",
    "            # Apply saliency weighting\n",
    "            weighted_img = gray.astype(np.float32) * saliency / 255.0\n",
    "            \n",
    "            # Resize and compute FFT\n",
    "            resized = cv2.resize(weighted_img, (128, 128))\n",
    "            fft = np.fft.fft2(resized)\n",
    "            fft_shift = np.fft.fftshift(fft)\n",
    "            magnitude = np.abs(fft_shift)\n",
    "            log_magnitude = np.log(magnitude + 1.0)\n",
    "            \n",
    "            # Extract central region\n",
    "            center = log_magnitude.shape[0] // 2\n",
    "            crop_size = 16\n",
    "            central_region = log_magnitude[center-crop_size:center+crop_size, \n",
    "                                         center-crop_size:center+crop_size]\n",
    "            \n",
    "            return central_region.flatten().astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return np.zeros(1024, dtype=np.float32)\n",
    "    \n",
    "    def compute_hu_moments(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute 7 Hu invariant moments from binary silhouette\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale and binary\n",
    "            if len(img.shape) == 3:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = img.copy()\n",
    "            \n",
    "            # Otsu thresholding for clean binary image\n",
    "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "            # Morphological cleaning\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "            binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "            \n",
    "            # Compute Hu moments\n",
    "            moments = cv2.moments(binary)\n",
    "            hu_moments = cv2.HuMoments(moments).flatten()\n",
    "            \n",
    "            # Log-transform for numerical stability\n",
    "            hu_log = []\n",
    "            for hu in hu_moments:\n",
    "                if hu > 0:\n",
    "                    hu_log.append(-np.log10(hu))\n",
    "                elif hu < 0:\n",
    "                    hu_log.append(-np.log10(-hu))\n",
    "                else:\n",
    "                    hu_log.append(0.0)\n",
    "            \n",
    "            return np.array(hu_log, dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return np.zeros(7, dtype=np.float32)\n",
    "    \n",
    "    def compute_zernike_moments(self, img: np.ndarray, max_order: int = 8) -> np.ndarray:\n",
    "        \"\"\"Compute Zernike moments up to specified order\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale and binary\n",
    "            if len(img.shape) == 3:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = img.copy()\n",
    "            \n",
    "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            binary_float = binary.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Resize for computation\n",
    "            size = 128\n",
    "            binary_resized = cv2.resize(binary_float, (size, size))\n",
    "            \n",
    "            height, width = binary_resized.shape\n",
    "            center_x, center_y = width // 2, height // 2\n",
    "            \n",
    "            # Create coordinate grids\n",
    "            x, y = np.ogrid[:height, :width]\n",
    "            x = x - center_y\n",
    "            y = y - center_x\n",
    "            \n",
    "            # Convert to polar coordinates\n",
    "            rho = np.sqrt(x**2 + y**2)\n",
    "            theta = np.arctan2(y, x)\n",
    "            \n",
    "            # Normalize rho to unit circle\n",
    "            max_rho = np.sqrt(center_x**2 + center_y**2)\n",
    "            rho = rho / max_rho\n",
    "            \n",
    "            # Create unit circle mask\n",
    "            unit_circle = (rho <= 1.0)\n",
    "            \n",
    "            zernike_moments = []\n",
    "            \n",
    "            # Compute moments for orders up to max_order (simplified)\n",
    "            for n in range(min(max_order + 1, 6)):  # Limit for performance\n",
    "                for m in range(-n, n + 1, 2):  # Only valid combinations\n",
    "                    if abs(m) <= n and (n - abs(m)) % 2 == 0:\n",
    "                        # Simplified Zernike computation\n",
    "                        moment_real = np.mean(binary_resized[unit_circle] * np.cos(m * theta[unit_circle]))\n",
    "                        moment_imag = np.mean(binary_resized[unit_circle] * np.sin(m * theta[unit_circle]))\n",
    "                        zernike_moments.extend([moment_real, moment_imag])\n",
    "            \n",
    "            return np.array(zernike_moments, dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return np.zeros(50, dtype=np.float32)\n",
    "    \n",
    "    def compute_texture_features(self, img: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Compute LBP, GLCM, and Gabor texture features\"\"\"\n",
    "        texture_features = {}\n",
    "        \n",
    "        try:\n",
    "            # Convert to grayscale if needed\n",
    "            if len(img.shape) == 3:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = img.copy()\n",
    "            \n",
    "            # LBP features\n",
    "            lbp = local_binary_pattern(gray, self.lbp_n_points, self.lbp_radius, method='uniform')\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=self.lbp_n_points + 2, \n",
    "                                 range=(0, self.lbp_n_points + 2), density=True)\n",
    "            \n",
    "            texture_features['lbp_uniformity'] = float(hist[:-1].sum())\n",
    "            texture_features['lbp_entropy'] = float(-np.sum(hist * np.log2(hist + 1e-10)))\n",
    "            texture_features['lbp_energy'] = float(np.sum(hist ** 2))\n",
    "            \n",
    "            # GLCM features (simplified)\n",
    "            gray_resized = cv2.resize(gray, (64, 64))  # Reduce size for speed\n",
    "            glcm = graycomatrix(gray_resized, distances=[1], angles=[0], levels=256, \n",
    "                               symmetric=True, normed=True)\n",
    "            \n",
    "            texture_features['glcm_contrast'] = float(graycoprops(glcm, 'contrast')[0, 0])\n",
    "            texture_features['glcm_correlation'] = float(graycoprops(glcm, 'correlation')[0, 0])\n",
    "            texture_features['glcm_energy'] = float(graycoprops(glcm, 'energy')[0, 0])\n",
    "            texture_features['glcm_homogeneity'] = float(graycoprops(glcm, 'homogeneity')[0, 0])\n",
    "            \n",
    "            # Gabor features (simplified - just 2 filters for speed)\n",
    "            gray_norm = gray.astype(np.float32) / 255.0\n",
    "            \n",
    "            gabor_responses = []\n",
    "            for freq in [0.1, 0.3]:\n",
    "                for angle in [0, np.pi/4]:\n",
    "                    try:\n",
    "                        filt_real, _ = gabor(gray_norm, frequency=freq, theta=angle)\n",
    "                        gabor_responses.extend([\n",
    "                            float(np.mean(filt_real)),\n",
    "                            float(np.std(filt_real)),\n",
    "                            float(np.mean(filt_real ** 2))\n",
    "                        ])\n",
    "                    except Exception:\n",
    "                        gabor_responses.extend([0.0, 0.0, 0.0])\n",
    "            \n",
    "            # Add Gabor responses to features\n",
    "            for i, response in enumerate(gabor_responses):\n",
    "                texture_features[f'gabor_{i}'] = response\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return default values on error\n",
    "            default_keys = ['lbp_uniformity', 'lbp_entropy', 'lbp_energy', \n",
    "                           'glcm_contrast', 'glcm_correlation', 'glcm_energy', 'glcm_homogeneity']\n",
    "            for key in default_keys:\n",
    "                texture_features[key] = 0.0\n",
    "            for i in range(12):  # Gabor features\n",
    "                texture_features[f'gabor_{i}'] = 0.0\n",
    "        \n",
    "        return texture_features\n",
    "    \n",
    "    def compute_enhanced_color_features(self, img: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Enhanced color analysis across multiple color spaces\"\"\"\n",
    "        color_features = {}\n",
    "        \n",
    "        try:\n",
    "            if len(img.shape) == 3:\n",
    "                # Color moments in RGB\n",
    "                for c, channel in enumerate(['R', 'G', 'B']):\n",
    "                    pixels = img[:, :, c].flatten().astype(np.float32) / 255.0\n",
    "                    color_features[f'color_{channel}_mean'] = float(np.mean(pixels))\n",
    "                    color_features[f'color_{channel}_std'] = float(np.std(pixels))\n",
    "                    color_features[f'color_{channel}_skewness'] = float(skew(pixels))\n",
    "                \n",
    "                # HSV analysis\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                for c, channel in enumerate(['H', 'S', 'V']):\n",
    "                    pixels = hsv[:, :, c].flatten().astype(np.float32) / 255.0\n",
    "                    color_features[f'color_hsv_{channel}_mean'] = float(np.mean(pixels))\n",
    "                    color_features[f'color_hsv_{channel}_std'] = float(np.std(pixels))\n",
    "                \n",
    "                # Dominant colors (simplified k-means)\n",
    "                pixels_rgb = img.reshape(-1, 3).astype(np.float32)\n",
    "                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "                _, labels, centers = cv2.kmeans(pixels_rgb, 3, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "                \n",
    "                # Sort centers by frequency\n",
    "                unique, counts = np.unique(labels, return_counts=True)\n",
    "                sorted_indices = np.argsort(counts)[::-1]\n",
    "                \n",
    "                for i, idx in enumerate(sorted_indices):\n",
    "                    center = centers[idx] / 255.0\n",
    "                    color_features[f'color_dominant_{i}_r'] = float(center[2])\n",
    "                    color_features[f'color_dominant_{i}_g'] = float(center[1])\n",
    "                    color_features[f'color_dominant_{i}_b'] = float(center[0])\n",
    "                    color_features[f'color_dominant_{i}_freq'] = float(counts[idx] / len(labels))\n",
    "            else:\n",
    "                # Grayscale - set defaults\n",
    "                for channel in ['R', 'G', 'B']:\n",
    "                    for stat in ['mean', 'std', 'skewness']:\n",
    "                        color_features[f'color_{channel}_{stat}'] = 0.0\n",
    "                for channel in ['H', 'S', 'V']:\n",
    "                    for stat in ['mean', 'std']:\n",
    "                        color_features[f'color_hsv_{channel}_{stat}'] = 0.0\n",
    "                for i in range(3):\n",
    "                    for c in ['r', 'g', 'b']:\n",
    "                        color_features[f'color_dominant_{i}_{c}'] = 0.0\n",
    "                    color_features[f'color_dominant_{i}_freq'] = 0.0\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Return defaults on error\n",
    "            for channel in ['R', 'G', 'B']:\n",
    "                for stat in ['mean', 'std', 'skewness']:\n",
    "                    color_features[f'color_{channel}_{stat}'] = 0.0\n",
    "            for channel in ['H', 'S', 'V']:\n",
    "                for stat in ['mean', 'std']:\n",
    "                    color_features[f'color_hsv_{channel}_{stat}'] = 0.0\n",
    "            for i in range(3):\n",
    "                for c in ['r', 'g', 'b']:\n",
    "                    color_features[f'color_dominant_{i}_{c}'] = 0.0\n",
    "                color_features[f'color_dominant_{i}_freq'] = 0.0\n",
    "        \n",
    "        return color_features\n",
    "    \n",
    "    def mean_color_features(self, img: Image.Image) -> List[float]:\n",
    "        \"\"\"Compute compact color signature for clustering\"\"\"\n",
    "        try:\n",
    "            im = img.convert(\"RGB\").resize((256, 256), Image.BICUBIC)\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "            \n",
    "            # RGB means\n",
    "            r_mean = float(arr[..., 0].mean())\n",
    "            g_mean = float(arr[..., 1].mean())  \n",
    "            b_mean = float(arr[..., 2].mean())\n",
    "            \n",
    "            # Convert to HSV\n",
    "            hsv = np.zeros_like(arr)\n",
    "            for i in range(arr.shape[0]):\n",
    "                for j in range(arr.shape[1]):\n",
    "                    hsv[i, j] = colorsys.rgb_to_hsv(arr[i, j, 0], arr[i, j, 1], arr[i, j, 2])\n",
    "            \n",
    "            H, S, V = hsv[..., 0], hsv[..., 1], hsv[..., 2]\n",
    "            \n",
    "            # Circular mean for hue\n",
    "            ang = 2 * np.pi * H\n",
    "            h_mean = float((np.arctan2(np.sin(ang).mean(), np.cos(ang).mean()) % (2 * np.pi)) / (2 * np.pi))\n",
    "            s_mean = float(S.mean())\n",
    "            v_mean = float(V.mean())\n",
    "            \n",
    "            return [r_mean, g_mean, b_mean, s_mean, v_mean]\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def compute_sift_features(self, img: np.ndarray) -> Dict:\n",
    "        \"\"\"Compute SIFT keypoints and descriptors for logo matching\"\"\"\n",
    "        try:\n",
    "            sift = cv2.SIFT_create(nfeatures=100)\n",
    "            keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "            \n",
    "            if descriptors is None or len(descriptors) == 0:\n",
    "                return {'valid': False, 'signature': np.zeros(256)}\n",
    "            \n",
    "            desc_mean = np.mean(descriptors, axis=0) if len(descriptors) > 0 else np.zeros(128)\n",
    "            desc_std = np.std(descriptors, axis=0) if len(descriptors) > 0 else np.zeros(128)\n",
    "            \n",
    "            return {\n",
    "                'valid': True,\n",
    "                'keypoint_count': len(keypoints),\n",
    "                'descriptors': descriptors,\n",
    "                'signature': np.concatenate([desc_mean, desc_std])\n",
    "            }\n",
    "            \n",
    "        except Exception:\n",
    "            return {'valid': False, 'signature': np.zeros(256)}\n",
    "    \n",
    "    def compute_orb_features(self, img: np.ndarray) -> Dict:\n",
    "        \"\"\"Compute ORB keypoints and descriptors\"\"\"\n",
    "        try:\n",
    "            orb = cv2.ORB_create(nfeatures=50)\n",
    "            keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "            \n",
    "            if descriptors is None or len(descriptors) == 0:\n",
    "                return {'valid': False, 'signature': np.zeros(32)}\n",
    "            \n",
    "            desc_mean = np.mean(descriptors.astype(np.float32), axis=0) if len(descriptors) > 0 else np.zeros(32)\n",
    "            \n",
    "            return {\n",
    "                'valid': True,\n",
    "                'keypoint_count': len(keypoints),\n",
    "                'descriptors': descriptors,\n",
    "                'signature': desc_mean\n",
    "            }\n",
    "            \n",
    "        except Exception:\n",
    "            return {'valid': False, 'signature': np.zeros(32)}\n",
    "    \n",
    "    def compare_fourier_mellin(self, sig1: np.ndarray, sig2: np.ndarray) -> float:\n",
    "        \"\"\"Compare Fourier-Mellin signatures with rotation invariance\"\"\"\n",
    "        n = len(sig1)\n",
    "        \n",
    "        # Pad and compute correlation via FFT\n",
    "        sig1_fft = np.fft.rfft(sig1, n=2*n)\n",
    "        sig2_fft = np.fft.rfft(sig2[::-1], n=2*n)\n",
    "        \n",
    "        correlation = np.fft.irfft(sig1_fft * sig2_fft)\n",
    "        max_correlation = np.max(correlation)\n",
    "        \n",
    "        return max_correlation\n",
    "    \n",
    "    def match_sift_features(self, desc1: np.ndarray, desc2: np.ndarray) -> float:\n",
    "        \"\"\"Match SIFT descriptors using FLANN matcher\"\"\"\n",
    "        try:\n",
    "            if len(desc1) == 0 or len(desc2) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "            \n",
    "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "            matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "            \n",
    "            good_matches = []\n",
    "            for match_pair in matches:\n",
    "                if len(match_pair) == 2:\n",
    "                    m, n = match_pair\n",
    "                    if m.distance < 0.7 * n.distance:\n",
    "                        good_matches.append(m)\n",
    "            \n",
    "            total_features = min(len(desc1), len(desc2))\n",
    "            return len(good_matches) / max(total_features, 1)\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def match_orb_features(self, desc1: np.ndarray, desc2: np.ndarray) -> float:\n",
    "        \"\"\"Match ORB descriptors using Hamming distance\"\"\"\n",
    "        try:\n",
    "            if len(desc1) == 0 or len(desc2) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(desc1, desc2)\n",
    "            \n",
    "            good_matches = [m for m in matches if m.distance < 50]\n",
    "            \n",
    "            total_features = min(len(desc1), len(desc2))\n",
    "            return len(good_matches) / max(total_features, 1)\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def compute_deep_fused_hash(self, img: np.ndarray, hash_dim: int = 64) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Deep hashing inspired compact binary codes from arXiv:1610.07231\n",
    "        Fuses multiple visual cues into balanced binary representation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract core features for fusion\n",
    "            phash_bits = np.array([int(bit) for bit in self.compute_phash(img)], dtype=np.float32)\n",
    "            fft_vec = self.compute_fft_features(img)\n",
    "            fmt_sig = self.compute_fourier_mellin_signature(img)\n",
    "            hu_moments = self.compute_hu_moments(img)\n",
    "            \n",
    "            # Color and texture features (simplified for speed)\n",
    "            color_vec = []\n",
    "            try:\n",
    "                if len(img.shape) == 3:\n",
    "                    # Simple color moments\n",
    "                    for c in range(3):\n",
    "                        channel = img[:, :, c].flatten().astype(np.float32) / 255.0\n",
    "                        color_vec.extend([np.mean(channel), np.std(channel)])\n",
    "                else:\n",
    "                    color_vec = [0.5, 0.2] * 3  # Grayscale defaults\n",
    "            except:\n",
    "                color_vec = [0.5, 0.2] * 3\n",
    "            \n",
    "            # Multi-scale FFT (different crop sizes for deep-style multi-scale)\n",
    "            try:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
    "                # Small scale (32x32)\n",
    "                small_scale = cv2.resize(gray.astype(np.float32) / 255.0, (32, 32))\n",
    "                fft_small = np.fft.fft2(small_scale)\n",
    "                fft_small_mag = np.abs(np.fft.fftshift(fft_small))[12:20, 12:20].flatten()\n",
    "                \n",
    "                # Medium scale (64x64) \n",
    "                med_scale = cv2.resize(gray.astype(np.float32) / 255.0, (64, 64))\n",
    "                fft_med = np.fft.fft2(med_scale)\n",
    "                fft_med_mag = np.abs(np.fft.fftshift(fft_med))[28:36, 28:36].flatten()\n",
    "                \n",
    "                multi_scale_fft = np.concatenate([fft_small_mag, fft_med_mag])\n",
    "            except:\n",
    "                multi_scale_fft = np.zeros(128, dtype=np.float32)\n",
    "            \n",
    "            # Concatenate all features into fusion vector\n",
    "            feature_parts = [\n",
    "                phash_bits[:32],  # Limit pHash to 32 bits\n",
    "                fft_vec[:64],     # Limit FFT features\n",
    "                fmt_sig[:32],     # Limit FMT signature \n",
    "                hu_moments[:7],   # All Hu moments\n",
    "                np.array(color_vec[:6], dtype=np.float32),  # Color moments\n",
    "                multi_scale_fft[:32]  # Multi-scale texture\n",
    "            ]\n",
    "            \n",
    "            # Ensure all parts are valid\n",
    "            valid_parts = []\n",
    "            for part in feature_parts:\n",
    "                if part.size > 0:\n",
    "                    # Normalize each feature type independently (deep hashing principle)\n",
    "                    part_norm = (part - np.mean(part)) / (np.std(part) + 1e-8)\n",
    "                    valid_parts.append(part_norm)\n",
    "            \n",
    "            if not valid_parts:\n",
    "                return np.zeros(hash_dim, dtype=np.uint8)\n",
    "            \n",
    "            # Concatenate normalized features\n",
    "            concat_features = np.concatenate(valid_parts)\n",
    "            \n",
    "            # Ensure we have enough features for projection\n",
    "            if len(concat_features) < hash_dim:\n",
    "                # Pad with zeros if needed\n",
    "                padded = np.zeros(hash_dim)\n",
    "                padded[:len(concat_features)] = concat_features\n",
    "                concat_features = padded\n",
    "            \n",
    "            # Random orthogonal projection (simulates learned projection from deep hashing)\n",
    "            # Use deterministic seed based on image content for consistency\n",
    "            seed = int(np.sum(concat_features * 1000)) % 100000\n",
    "            np.random.seed(seed % 1000)  # Limit seed range\n",
    "            \n",
    "            # Create orthogonal projection matrix\n",
    "            proj_dim = min(hash_dim, len(concat_features))\n",
    "            if len(concat_features) >= proj_dim:\n",
    "                W = np.random.randn(len(concat_features), proj_dim)\n",
    "                W, _ = np.linalg.qr(W)  # Orthogonalize (ensures bit independence)\n",
    "                \n",
    "                # Project and binarize\n",
    "                projected = concat_features @ W\n",
    "                \n",
    "                # Bit balancing: center around 0 for even +/- distribution\n",
    "                projected = projected - np.median(projected)\n",
    "                \n",
    "                # Binarize with sign function\n",
    "                binary_hash = (projected > 0).astype(np.uint8)\n",
    "            else:\n",
    "                # Fallback for insufficient features\n",
    "                binary_hash = (concat_features[:proj_dim] > np.median(concat_features[:proj_dim])).astype(np.uint8)\n",
    "            \n",
    "            # Ensure output is exactly hash_dim length\n",
    "            if len(binary_hash) < hash_dim:\n",
    "                padded_hash = np.zeros(hash_dim, dtype=np.uint8)\n",
    "                padded_hash[:len(binary_hash)] = binary_hash\n",
    "                return padded_hash\n",
    "            else:\n",
    "                return binary_hash[:hash_dim]\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Return random-like but deterministic hash on failure\n",
    "            img_sum = np.sum(img.astype(np.float32)) if img is not None else 12345\n",
    "            np.random.seed(int(img_sum) % 10000)\n",
    "            return np.random.randint(0, 2, hash_dim, dtype=np.uint8)\n",
    "    \n",
    "    def compute_semantic_calibrated_similarity(self, features1: Dict, features2: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Semantic calibration inspired by deep hashing pairwise loss\n",
    "        Learns optimal weighting of multiple similarity cues\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Individual similarity scores\n",
    "            similarities = {}\n",
    "            \n",
    "            # 1. Deep fused hash similarity (Hamming distance)\n",
    "            if 'deep_fused_hash' in features1 and 'deep_fused_hash' in features2:\n",
    "                hash1, hash2 = features1['deep_fused_hash'], features2['deep_fused_hash']\n",
    "                if hash1 is not None and hash2 is not None and len(hash1) == len(hash2):\n",
    "                    hamming_dist = np.sum(hash1 != hash2)\n",
    "                    similarities['fused_hash'] = 1.0 - (hamming_dist / len(hash1))\n",
    "                else:\n",
    "                    similarities['fused_hash'] = 0.0\n",
    "            \n",
    "            # 2. Traditional pHash\n",
    "            if features1.get('phash') and features2.get('phash'):\n",
    "                hamming_dist = self.hamming_distance(features1['phash'], features2['phash'])\n",
    "                similarities['phash'] = 1.0 - (hamming_dist / 64.0)\n",
    "            \n",
    "            # 3. FFT similarity\n",
    "            if features1.get('fft_features') is not None and features2.get('fft_features') is not None:\n",
    "                try:\n",
    "                    fft_sim = cosine_similarity(\n",
    "                        features1['fft_features'].reshape(1, -1),\n",
    "                        features2['fft_features'].reshape(1, -1)\n",
    "                    )[0, 0]\n",
    "                    similarities['fft'] = max(0, fft_sim)\n",
    "                except:\n",
    "                    similarities['fft'] = 0.0\n",
    "            \n",
    "            # 4. Moment-based similarity\n",
    "            if features1.get('hu_moments') is not None and features2.get('hu_moments') is not None:\n",
    "                try:\n",
    "                    hu_sim = cosine_similarity(\n",
    "                        features1['hu_moments'].reshape(1, -1),\n",
    "                        features2['hu_moments'].reshape(1, -1)\n",
    "                    )[0, 0]\n",
    "                    similarities['moments'] = max(0, hu_sim)\n",
    "                except:\n",
    "                    similarities['moments'] = 0.0\n",
    "            \n",
    "            # 5. Color distance (inverted to similarity)\n",
    "            if features1.get('color_vector') and features2.get('color_vector'):\n",
    "                color_dist = self.color_distance(features1['color_vector'], features2['color_vector'])\n",
    "                similarities['color'] = max(0, 1.0 - color_dist / 2.0)\n",
    "            \n",
    "            # Calibrated fusion weights (inspired by deep hashing learned weights)\n",
    "            # These approximate what a logistic regression would learn\n",
    "            fusion_weights = {\n",
    "                'fused_hash': 0.35,  # Primary: compact multi-feature hash\n",
    "                'phash': 0.25,       # Secondary: proven perceptual hash  \n",
    "                'fft': 0.20,         # Tertiary: global shape\n",
    "                'moments': 0.15,     # Quaternary: geometric invariants\n",
    "                'color': 0.05        # Minimal: color (handled in fused hash)\n",
    "            }\n",
    "            \n",
    "            # Weighted similarity fusion\n",
    "            weighted_sum = 0.0\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            for method, similarity in similarities.items():\n",
    "                if method in fusion_weights and similarity > 0:\n",
    "                    weight = fusion_weights[method]\n",
    "                    weighted_sum += similarity * weight\n",
    "                    total_weight += weight\n",
    "            \n",
    "            # Normalize by total weights used\n",
    "            if total_weight > 0:\n",
    "                calibrated_score = weighted_sum / total_weight\n",
    "            else:\n",
    "                calibrated_score = 0.0\n",
    "            \n",
    "            return float(calibrated_score)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "\n",
    "    def compute_all_features(self, img: np.ndarray) -> Dict:\n",
    "        \"\"\"Compute ALL features including 2025 research + deep hashing enhancements\"\"\"\n",
    "        # Traditional Fourier features\n",
    "        fourier_features = {\n",
    "            'phash': self.compute_phash(img),\n",
    "            'fft_features': self.compute_fft_features(img),\n",
    "            'fmt_signature': self.compute_fourier_mellin_signature(img)\n",
    "        }\n",
    "        \n",
    "        # Advanced 2025 research features\n",
    "        fourier_features['color_aware_fmt'] = self.compute_color_aware_fmt(img)\n",
    "        fourier_features['saliency_weighted_fft'] = self.compute_saliency_weighted_fft(img)\n",
    "        fourier_features['hu_moments'] = self.compute_hu_moments(img)\n",
    "        fourier_features['zernike_moments'] = self.compute_zernike_moments(img)\n",
    "        \n",
    "        # Deep hashing inspired features (NEW)\n",
    "        fourier_features['deep_fused_hash'] = self.compute_deep_fused_hash(img, hash_dim=64)\n",
    "        \n",
    "        # Texture features\n",
    "        texture_features = self.compute_texture_features(img)\n",
    "        fourier_features.update(texture_features)\n",
    "        \n",
    "        # Enhanced color features\n",
    "        color_features = self.compute_enhanced_color_features(img)\n",
    "        fourier_features.update(color_features)\n",
    "        \n",
    "        # Keypoint features\n",
    "        sift_features = self.compute_sift_features(img)\n",
    "        orb_features = self.compute_orb_features(img)\n",
    "        \n",
    "        fourier_features.update({\n",
    "            'sift': sift_features,\n",
    "            'orb': orb_features\n",
    "        })\n",
    "        \n",
    "        return fourier_features\n",
    "    \n",
    "    def are_similar(self, features1: Dict, features2: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Enhanced similarity using ALL 2025 research + deep hashing methods\"\"\"\n",
    "        \n",
    "        # Deep hashing calibrated similarity (PRIMARY METHOD)\n",
    "        calibrated_similarity = self.compute_semantic_calibrated_similarity(features1, features2)\n",
    "        calibrated_similar = calibrated_similarity >= 0.75  # Learned threshold\n",
    "        \n",
    "        # Deep fused hash Hamming distance\n",
    "        fused_hash_similar = False\n",
    "        fused_hamming_distance = 64\n",
    "        if features1.get('deep_fused_hash') is not None and features2.get('deep_fused_hash') is not None:\n",
    "            hash1, hash2 = features1['deep_fused_hash'], features2['deep_fused_hash']\n",
    "            if len(hash1) == len(hash2):\n",
    "                fused_hamming_distance = np.sum(hash1 != hash2)\n",
    "                # Deep hashing typically uses lower thresholds due to better bit distribution\n",
    "                fused_hash_similar = fused_hamming_distance <= (len(hash1) * 0.25)  # 25% threshold\n",
    "        \n",
    "        # Traditional pHash comparison (SECONDARY)\n",
    "        phash_distance = self.hamming_distance(features1['phash'], features2['phash'])\n",
    "        phash_similar = phash_distance <= self.similarity_threshold_phash\n",
    "        \n",
    "        # FFT features comparison\n",
    "        fft_similarity = cosine_similarity(\n",
    "            features1['fft_features'].reshape(1, -1),\n",
    "            features2['fft_features'].reshape(1, -1)\n",
    "        )[0, 0]\n",
    "        fft_similar = fft_similarity >= self.similarity_threshold_fft\n",
    "        \n",
    "        # Fourier-Mellin comparison\n",
    "        fmt_similarity = self.compare_fourier_mellin(\n",
    "            features1['fmt_signature'],\n",
    "            features2['fmt_signature']\n",
    "        )\n",
    "        fmt_similar = fmt_similarity >= self.similarity_threshold_fmt\n",
    "        \n",
    "        # Advanced 2025 features comparison\n",
    "        # Color-aware Fourier-Mellin\n",
    "        color_fmt_similarity = cosine_similarity(\n",
    "            features1['color_aware_fmt'].reshape(1, -1),\n",
    "            features2['color_aware_fmt'].reshape(1, -1)\n",
    "        )[0, 0] if features1['color_aware_fmt'].size > 0 else 0.0\n",
    "        color_fmt_similar = color_fmt_similarity >= 0.85\n",
    "        \n",
    "        # Saliency-weighted FFT\n",
    "        saliency_fft_similarity = cosine_similarity(\n",
    "            features1['saliency_weighted_fft'].reshape(1, -1),\n",
    "            features2['saliency_weighted_fft'].reshape(1, -1)\n",
    "        )[0, 0] if features1['saliency_weighted_fft'].size > 0 else 0.0\n",
    "        saliency_fft_similar = saliency_fft_similarity >= 0.80\n",
    "        \n",
    "        # Hu moments\n",
    "        hu_similarity = cosine_similarity(\n",
    "            features1['hu_moments'].reshape(1, -1),\n",
    "            features2['hu_moments'].reshape(1, -1)\n",
    "        )[0, 0] if features1['hu_moments'].size > 0 else 0.0\n",
    "        hu_similar = hu_similarity >= 0.75\n",
    "        \n",
    "        # Zernike moments\n",
    "        zernike_similarity = cosine_similarity(\n",
    "            features1['zernike_moments'].reshape(1, -1),\n",
    "            features2['zernike_moments'].reshape(1, -1)\n",
    "        )[0, 0] if features1['zernike_moments'].size > 0 else 0.0\n",
    "        zernike_similar = zernike_similarity >= 0.70\n",
    "        \n",
    "        # SIFT/ORB keypoint matching\n",
    "        sift_similarity = 0.0\n",
    "        sift_similar = False\n",
    "        if features1['sift']['valid'] and features2['sift']['valid']:\n",
    "            sift_similarity = self.match_sift_features(\n",
    "                features1['sift']['descriptors'], \n",
    "                features2['sift']['descriptors']\n",
    "            )\n",
    "            if len(features1['sift']['signature']) > 0:\n",
    "                sift_sig_similarity = cosine_similarity(\n",
    "                    features1['sift']['signature'].reshape(1, -1),\n",
    "                    features2['sift']['signature'].reshape(1, -1)\n",
    "                )[0, 0]\n",
    "                sift_similarity = max(sift_similarity, sift_sig_similarity)\n",
    "            sift_similar = sift_similarity >= 0.3\n",
    "        \n",
    "        orb_similarity = 0.0\n",
    "        orb_similar = False\n",
    "        if features1['orb']['valid'] and features2['orb']['valid']:\n",
    "            orb_similarity = self.match_orb_features(\n",
    "                features1['orb']['descriptors'], \n",
    "                features2['orb']['descriptors']\n",
    "            )\n",
    "            if len(features1['orb']['signature']) > 0:\n",
    "                orb_sig_similarity = cosine_similarity(\n",
    "                    features1['orb']['signature'].reshape(1, -1),\n",
    "                    features2['orb']['signature'].reshape(1, -1)\n",
    "                )[0, 0]\n",
    "                orb_similarity = max(orb_similarity, orb_sig_similarity)\n",
    "            orb_similar = orb_similarity >= 0.25\n",
    "        \n",
    "        # Deep hashing inspired similarity decision with hierarchical confidence\n",
    "        # Primary: Calibrated similarity (combines multiple cues intelligently)\n",
    "        # Secondary: Individual method agreement for validation\n",
    "        \n",
    "        confidence_methods = [\n",
    "            calibrated_similar,     # Primary: learned fusion\n",
    "            fused_hash_similar,     # Secondary: compact binary hash\n",
    "            phash_similar,          # Traditional: perceptual hash\n",
    "            fft_similar or fmt_similar,  # Shape: global structure\n",
    "            hu_similar or zernike_similar,  # Geometry: invariant moments\n",
    "            sift_similar or orb_similar     # Local: keypoint features\n",
    "        ]\n",
    "        \n",
    "        # Multi-tier decision (inspired by deep hashing confidence)\n",
    "        confidence_score = sum(confidence_methods) / len(confidence_methods)\n",
    "        \n",
    "        # Enhanced decision logic with confidence thresholding\n",
    "        if calibrated_similarity >= 0.85:\n",
    "            # High confidence from calibrated fusion\n",
    "            is_similar = True\n",
    "        elif confidence_score >= 0.5 and calibrated_similar:\n",
    "            # Medium confidence with method agreement\n",
    "            is_similar = True  \n",
    "        elif fused_hash_similar and (phash_similar or fft_similar):\n",
    "            # Backup: compact hash + traditional method\n",
    "            is_similar = True\n",
    "        else:\n",
    "            # Fallback to traditional multi-method OR\n",
    "            is_similar = (phash_similar or fft_similar or fmt_similar or \n",
    "                         color_fmt_similar or saliency_fft_similar or \n",
    "                         hu_similar or zernike_similar or sift_similar or orb_similar)\n",
    "        \n",
    "        metrics = {\n",
    "            # Deep hashing metrics (NEW)\n",
    "            'calibrated_similarity': calibrated_similarity,\n",
    "            'calibrated_similar': calibrated_similar,\n",
    "            'fused_hash_distance': fused_hamming_distance,\n",
    "            'fused_hash_similar': fused_hash_similar,\n",
    "            'confidence_score': confidence_score,\n",
    "            \n",
    "            # Traditional metrics (EXISTING)\n",
    "            'phash_distance': phash_distance,\n",
    "            'phash_similar': phash_similar,\n",
    "            'fft_similarity': fft_similarity,\n",
    "            'fft_similar': fft_similar,\n",
    "            'fmt_similarity': fmt_similarity,\n",
    "            'fmt_similar': fmt_similar,\n",
    "            'color_fmt_similarity': color_fmt_similarity,\n",
    "            'color_fmt_similar': color_fmt_similar,\n",
    "            'saliency_fft_similarity': saliency_fft_similarity,\n",
    "            'saliency_fft_similar': saliency_fft_similar,\n",
    "            'hu_similarity': hu_similarity,\n",
    "            'hu_similar': hu_similar,\n",
    "            'zernike_similarity': zernike_similarity,\n",
    "            'zernike_similar': zernike_similar,\n",
    "            'sift_similarity': sift_similarity,\n",
    "            'sift_similar': sift_similar,\n",
    "            'orb_similarity': orb_similarity,\n",
    "            'orb_similar': orb_similar,\n",
    "            'overall_similar': is_similar\n",
    "        }\n",
    "        \n",
    "        return is_similar, metrics\n",
    "    \n",
    "    def preprocess_logo(self, logo_data: bytes) -> Optional[np.ndarray]:\n",
    "        \"\"\"Convert logo bytes to numpy array\"\"\"\n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(logo_data))\n",
    "            \n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            image = image.resize((128, 128), Image.Resampling.LANCZOS)\n",
    "            img_array = np.array(image)\n",
    "            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            return img_bgr\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def analyze_logo_batch(self, logos: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Analyze batch of logos with ALL 2025 research features\"\"\"\n",
    "        print(f\" Analyzing {len(logos)} logos with 2025 research features...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        analyzed_logos = []\n",
    "        successful_analysis = 0\n",
    "        \n",
    "        for i, logo in enumerate(logos):\n",
    "            if i % 50 == 0 and i > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = i / elapsed\n",
    "                eta = (len(logos) - i) / rate if rate > 0 else 0\n",
    "                print(f\"   Progress: {i}/{len(logos)} ({i/len(logos)*100:.1f}%) - ETA: {eta:.1f}s\")\n",
    "            \n",
    "            try:\n",
    "                img = self.preprocess_logo(logo['logo_data'])\n",
    "                \n",
    "                if img is not None:\n",
    "                    # Extract ALL features including 2025 research enhancements\n",
    "                    features = self.compute_all_features(img)\n",
    "                    \n",
    "                    # Extract color features for clustering\n",
    "                    try:\n",
    "                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        pil_img = Image.fromarray(img_rgb)\n",
    "                        color_features = self.mean_color_features(pil_img)\n",
    "                        features['color_vector'] = color_features\n",
    "                    except Exception:\n",
    "                        features['color_vector'] = None\n",
    "                    \n",
    "                    features['valid'] = True\n",
    "                    successful_analysis += 1\n",
    "                else:\n",
    "                    features = {'valid': False, 'color_vector': None}\n",
    "                \n",
    "                logo_with_features = logo.copy()\n",
    "                logo_with_features['features'] = features\n",
    "                analyzed_logos.append(logo_with_features)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logo_with_features = logo.copy()\n",
    "                logo_with_features['features'] = {'valid': False, 'error': str(e)}\n",
    "                analyzed_logos.append(logo_with_features)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\" Enhanced analysis completed: {successful_analysis}/{len(logos)} valid in {elapsed:.1f}s\")\n",
    "        print(f\" Features per logo: Traditional + 2025 Research + Deep Hashing\")\n",
    "        print(f\" Deep features: 64-bit fused hash + semantic calibration + multi-scale analysis\")\n",
    "        \n",
    "        return analyzed_logos\n",
    "    \n",
    "    def find_similar_pairs(self, analyzed_logos: List[Dict], threshold: float = 0.7) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"Find similar pairs using enhanced multi-method comparison\"\"\"\n",
    "        print(f\" Finding similar pairs with 2025 research methods (threshold: {threshold})...\")\n",
    "        \n",
    "        valid_logos = [logo for logo in analyzed_logos if logo['features']['valid']]\n",
    "        similar_pairs = []\n",
    "        \n",
    "        total_comparisons = len(valid_logos) * (len(valid_logos) - 1) // 2\n",
    "        comparison_count = 0\n",
    "        \n",
    "        for i in range(len(valid_logos)):\n",
    "            for j in range(i + 1, len(valid_logos)):\n",
    "                comparison_count += 1\n",
    "                \n",
    "                if comparison_count % 1000 == 0:\n",
    "                    progress = comparison_count / total_comparisons * 100\n",
    "                    print(f\"   Progress: {comparison_count}/{total_comparisons} ({progress:.1f}%)\")\n",
    "                \n",
    "                try:\n",
    "                    logo1, logo2 = valid_logos[i], valid_logos[j]\n",
    "                    is_similar, metrics = self.are_similar(logo1['features'], logo2['features'])\n",
    "                    \n",
    "                    if is_similar:\n",
    "                        # Enhanced similarity scoring with deep hashing\n",
    "                        # Primary: Use calibrated similarity score (learned fusion)\n",
    "                        composite_score = metrics.get('calibrated_similarity', 0.0)\n",
    "                        \n",
    "                        # Fallback: Traditional multi-method scoring if calibrated fails\n",
    "                        if composite_score < 0.1:\n",
    "                            similarity_scores = [\n",
    "                                1.0 - metrics['phash_distance'] / 64.0,\n",
    "                                metrics['fft_similarity'],\n",
    "                                metrics['fmt_similarity'],\n",
    "                                metrics['color_fmt_similarity'],\n",
    "                                metrics['saliency_fft_similarity'],\n",
    "                                metrics['hu_similarity'],\n",
    "                                metrics['zernike_similarity'],\n",
    "                                metrics['sift_similarity'],\n",
    "                                metrics['orb_similarity']\n",
    "                            ]\n",
    "                            \n",
    "                            # Take maximum similarity across all methods (best match)\n",
    "                            composite_score = max([s for s in similarity_scores if s > 0])\n",
    "                        \n",
    "                        if composite_score >= threshold:\n",
    "                            similar_pairs.append((\n",
    "                                logo1['website'],\n",
    "                                logo2['website'], \n",
    "                                composite_score\n",
    "                            ))\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        print(f\" Similar pairs found: {len(similar_pairs)} using deep hashing + multi-method analysis\")\n",
    "        print(f\" Deep hashing: Compact binary fusion + semantic calibration from arXiv:1610.07231\")\n",
    "        return similar_pairs\n",
    "\n",
    "print(\" Enhanced FourierLogoAnalyzer Ready!\")\n",
    "print(\" Features: Traditional Fourier + Advanced research + Deep hashing\")\n",
    "print(\" Multi-method similarity detection with compact binary codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogoVisualizationPipeline:\n",
    "    \"\"\"Create visualizations for logo analysis results\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_loaded = False\n",
    "        self.extraction_data = None\n",
    "        self.analyzed_logos = None\n",
    "        self.similar_pairs = None\n",
    "        self.clusters = None\n",
    "        \n",
    "    def load_results_from_memory(self, extraction_data, analyzed_logos, similar_pairs, clusters):\n",
    "        \"\"\"Load results from memory (for notebook use)\"\"\"\n",
    "        self.extraction_data = extraction_data\n",
    "        self.analyzed_logos = analyzed_logos\n",
    "        self.similar_pairs = similar_pairs\n",
    "        self.clusters = clusters\n",
    "        self.results_loaded = True\n",
    "        print(\"Results loaded into visualizer\")\n",
    "    \n",
    "    def create_extraction_performance_chart(self):\n",
    "        \"\"\"Create extraction performance visualization\"\"\"\n",
    "        if not self.results_loaded:\n",
    "            print(\" No results loaded\")\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Extraction success breakdown\n",
    "        successful = len(self.extraction_data['successful_logos'])\n",
    "        total = len(self.extraction_data['websites'])\n",
    "        failed = total - successful\n",
    "        \n",
    "        # Create subplot layout\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Logo Extraction Performance Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Success Rate Pie Chart\n",
    "        labels = ['Successful', 'Failed']\n",
    "        sizes = [successful, failed]\n",
    "        colors = ['#2E8B57', '#DC143C']\n",
    "        \n",
    "        ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "        ax1.set_title(f'Extraction Success Rate\\n({successful}/{total} websites)')\n",
    "        \n",
    "        # 2. Tier Usage (if available)\n",
    "        tier_counts = defaultdict(int)\n",
    "        for logo in self.extraction_data['successful_logos']:\n",
    "            tier = logo.get('tier_used', 'Unknown')\n",
    "            tier_counts[f\"Tier {tier}\"] += 1\n",
    "        \n",
    "        if tier_counts:\n",
    "            tiers = list(tier_counts.keys())\n",
    "            counts = list(tier_counts.values())\n",
    "            \n",
    "            ax2.bar(tiers, counts, color='#4682B4')\n",
    "            ax2.set_title('Success by API Tier')\n",
    "            ax2.set_ylabel('Number of Logos')\n",
    "            plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        # 3. Logo File Sizes Distribution\n",
    "        sizes = []\n",
    "        for logo in self.extraction_data['successful_logos']:\n",
    "            if 'logo_data' in logo and logo['logo_data']:\n",
    "                sizes.append(len(logo['logo_data']))\n",
    "        \n",
    "        if sizes:\n",
    "            ax3.hist(sizes, bins=20, color='#FF6347', alpha=0.7)\n",
    "            ax3.set_title('Logo File Size Distribution')\n",
    "            ax3.set_xlabel('File Size (bytes)')\n",
    "            ax3.set_ylabel('Count')\n",
    "        \n",
    "        # 4. Feature Analysis Success\n",
    "        if self.analyzed_logos:\n",
    "            valid_features = sum(1 for logo in self.analyzed_logos if logo.get('features', {}).get('valid', False))\n",
    "            invalid_features = len(self.analyzed_logos) - valid_features\n",
    "            \n",
    "            ax4.bar(['Valid Features', 'Invalid Features'], [valid_features, invalid_features], \n",
    "                   color=['#32CD32', '#FF4500'])\n",
    "            ax4.set_title('Feature Extraction Success')\n",
    "            ax4.set_ylabel('Number of Logos')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('extraction_performance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Extraction performance chart created\")\n",
    "    \n",
    "    def create_similarity_analysis_chart(self):\n",
    "        \"\"\"Create similarity analysis visualization\"\"\"\n",
    "        if not self.results_loaded or not self.similar_pairs:\n",
    "            print(\"No similarity data available\")\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Create subplot layout  \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Logo Similarity Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Extract similarity scores\n",
    "        similarity_scores = [pair[2] for pair in self.similar_pairs if len(pair) >= 3]\n",
    "        \n",
    "        # 1. Similarity Score Distribution\n",
    "        if similarity_scores:\n",
    "            ax1.hist(similarity_scores, bins=20, color='#9370DB', alpha=0.7, edgecolor='black')\n",
    "            ax1.axvline(np.mean(similarity_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(similarity_scores):.3f}')\n",
    "            ax1.set_title('Similarity Score Distribution')\n",
    "            ax1.set_xlabel('Similarity Score')\n",
    "            ax1.set_ylabel('Number of Pairs')\n",
    "            ax1.legend()\n",
    "        \n",
    "        # 2. Cluster Size Distribution\n",
    "        if self.clusters:\n",
    "            cluster_sizes = [len(cluster) for cluster in self.clusters if len(cluster) > 1]\n",
    "            \n",
    "            if cluster_sizes:\n",
    "                ax2.hist(cluster_sizes, bins=max(10, len(set(cluster_sizes))), \n",
    "                        color='#20B2AA', alpha=0.7, edgecolor='black')\n",
    "                ax2.set_title('Brand Cluster Size Distribution')\n",
    "                ax2.set_xlabel('Cluster Size (websites)')\n",
    "                ax2.set_ylabel('Number of Clusters')\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, 'No multi-website clusters found', \n",
    "                        ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "                ax2.set_title('Cluster Analysis')\n",
    "        \n",
    "        # 3. Top Similar Pairs\n",
    "        if similarity_scores:\n",
    "            top_pairs = sorted(self.similar_pairs, key=lambda x: x[2] if len(x) >= 3 else 0, reverse=True)[:10]\n",
    "            \n",
    "            pair_labels = []\n",
    "            scores = []\n",
    "            \n",
    "            for i, pair in enumerate(top_pairs):\n",
    "                website1 = pair[0].replace('https://', '').replace('http://', '').split('/')[0]\n",
    "                website2 = pair[1].replace('https://', '').replace('http://', '').split('/')[0] \n",
    "                \n",
    "                # Shorten domain names for display\n",
    "                domain1 = website1.split('.')[-2] if '.' in website1 else website1\n",
    "                domain2 = website2.split('.')[-2] if '.' in website2 else website2\n",
    "                \n",
    "                pair_labels.append(f\"{domain1}-{domain2}\")\n",
    "                scores.append(pair[2])\n",
    "            \n",
    "            if scores:\n",
    "                bars = ax3.barh(range(len(scores)), scores, color=plt.cm.viridis(np.linspace(0, 1, len(scores))))\n",
    "                ax3.set_yticks(range(len(scores)))\n",
    "                ax3.set_yticklabels(pair_labels)\n",
    "                ax3.set_title('Top 10 Most Similar Logo Pairs')\n",
    "                ax3.set_xlabel('Similarity Score')\n",
    "                \n",
    "                # Add value labels\n",
    "                for i, (bar, score) in enumerate(zip(bars, scores)):\n",
    "                    ax3.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                            f'{score:.3f}', va='center', fontsize=9)\n",
    "        \n",
    "        # 4. Summary Statistics\n",
    "        stats_text = f\"\"\"Analysis Summary:\n",
    "        \n",
    "• Total Websites: {len(self.extraction_data['websites'])}\n",
    "• Successful Extractions: {len(self.extraction_data['successful_logos'])}\n",
    "• Valid Features: {len(self.analyzed_logos) if self.analyzed_logos else 0}\n",
    "• Similar Pairs Found: {len(self.similar_pairs)}\n",
    "• Brand Clusters: {len([c for c in self.clusters if len(c) > 1]) if self.clusters else 0}\n",
    "• Largest Cluster: {max(len(c) for c in self.clusters) if self.clusters else 0} logos\n",
    "\n",
    "Success Rates:\n",
    "• Extraction: {len(self.extraction_data['successful_logos'])/len(self.extraction_data['websites'])*100:.1f}%\n",
    "• Feature Analysis: {len(self.analyzed_logos)/len(self.extraction_data['successful_logos'])*100:.1f if self.analyzed_logos else 0}%\"\"\"\n",
    "        \n",
    "        ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, fontsize=11,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "        ax4.set_xlim(0, 1)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.axis('off')\n",
    "        ax4.set_title('Pipeline Statistics')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('similarity_analysis_visualization.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Similarity analysis chart created\")\n",
    "    \n",
    "    def create_all_visualizations(self):\n",
    "        \"\"\"Create all visualization charts\"\"\"\n",
    "        print(\"\\n CREATING COMPREHENSIVE VISUALIZATIONS\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            self.create_extraction_performance_chart()\n",
    "            print()\n",
    "            self.create_similarity_analysis_chart()\n",
    "            \n",
    "            print(f\"\\nAll visualizations completed!\")\n",
    "            print(\"Charts saved as PNG files in current directory\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Visualization error: {e}\")\n",
    "            print(\"Continuing without visualizations...\")\n",
    "\n",
    "# Color distance function for clustering\n",
    "def color_distance(a, b):\n",
    "    \"\"\"Calculate Euclidean distance between two color vectors\"\"\"\n",
    "    if not a or not b:\n",
    "        return 0.0  # Treat as pass when missing data\n",
    "    \n",
    "    aa = np.array(a, dtype=np.float32)\n",
    "    bb = np.array(b, dtype=np.float32)\n",
    "    return float(np.linalg.norm(aa - bb))\n",
    "\n",
    "def color_distance(a, b):\n",
    "    \"\"\"Compute Euclidean distance between color vectors\"\"\"\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "# Complete Enhanced Pipeline Function\n",
    "async def run_enhanced_logo_analysis_pipeline(sample_size=None, max_tier=5, create_visuals=True, \n",
    "                                            color_gate=True, color_threshold=0.20):\n",
    "    \"\"\"\n",
    "    Complete enhanced logo analysis pipeline with ALL 2025 research features:\n",
    "    - 49-service API pool for 98%+ extraction success\n",
    "    - Advanced Fourier analysis (pHash, FFT, Fourier-Mellin)\n",
    "    - 2025 Research features (Hu/Zernike moments, texture analysis, saliency weighting)\n",
    "    - Color-aware clustering with configurable gating\n",
    "    - SIFT/ORB keypoint matching\n",
    "    - Multi-method similarity fusion\n",
    "    - Comprehensive visualizations\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\" ENHANCED LOGO ANALYSIS PIPELINE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\" 49-service API pool targeting 98%+ extraction success\")\n",
    "    print(\" Traditional + Advanced feature extraction (Moments, Texture, Color)\")\n",
    "    print(\" Multi-method similarity detection (9 different approaches)\")\n",
    "    print(\" Color-aware clustering with configurable gating\")\n",
    "    print()\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # Step 1: Load Data\n",
    "    print(\" STEP 1: DATA LOADING\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    df = LightningParquetProcessor.load_parquet_fast(\n",
    "        'logos.snappy.parquet', \n",
    "        sample_size=sample_size\n",
    "    )\n",
    "    \n",
    "    website_col = LightningParquetProcessor.get_website_column(df)\n",
    "    websites = df[website_col].dropna().tolist()\n",
    "    \n",
    "    print(f\" Processing {len(websites)} websites\")\n",
    "    \n",
    "    # Step 2: Enhanced Logo Extraction\n",
    "    print(f\"\\n STEP 2: ENHANCED LOGO EXTRACTION (Max Tier: {max_tier})\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    async with EnhancedAPILogoExtractor() as extractor:\n",
    "        logo_results = await extractor.batch_extract_logos_enhanced(websites, max_tier=max_tier)\n",
    "    \n",
    "    successful_logos = [r for r in logo_results if r['logo_found']]\n",
    "    success_rate = len(successful_logos) / len(websites) * 100\n",
    "    \n",
    "    print(f\" Logo extraction: {len(successful_logos)}/{len(websites)} ({success_rate:.1f}% success)\")\n",
    "    \n",
    "    if len(successful_logos) < 2:\n",
    "        print(\" Need at least 2 logos for similarity analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Enhanced Feature Analysis with 2025 Research\n",
    "    print(f\"\\n STEP 3: ENHANCED FEATURE ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    analyzer = FourierLogoAnalyzer()\n",
    "    analyzed_logos = analyzer.analyze_logo_batch(successful_logos)\n",
    "    valid_logos = [logo for logo in analyzed_logos if logo['features']['valid']]\n",
    "    \n",
    "    print(f\" Feature analysis: {len(valid_logos)}/{len(successful_logos)} logos with valid features\")\n",
    "    print(\" Features extracted: Traditional Fourier + 2025 Research + Keypoints + Texture + Enhanced Color\")\n",
    "    \n",
    "    if len(valid_logos) < 2:\n",
    "        print(\" Need at least 2 valid logos for similarity analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Step 4: Enhanced Multi-Method Similarity Analysis\n",
    "    print(f\"\\n STEP 4: MULTI-METHOD SIMILARITY ANALYSIS\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    similar_pairs = analyzer.find_similar_pairs(analyzed_logos, threshold=0.7)\n",
    "    print(f\" Similarity analysis: {len(similar_pairs)} similar pairs found using 9 detection methods\")\n",
    "    \n",
    "    # Step 5: Color-Aware Union-Find Clustering\n",
    "    print(f\"\\n STEP 5: COLOR-AWARE CLUSTERING\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Color gate: {'ENABLED' if color_gate else 'DISABLED'}\")\n",
    "    if color_gate:\n",
    "        print(f\"Color threshold: {color_threshold}\")\n",
    "    \n",
    "    if similar_pairs:\n",
    "        # Get all websites from valid logos\n",
    "        all_websites = [logo['website'] for logo in valid_logos]\n",
    "        \n",
    "        # Enhanced Union-Find with color awareness\n",
    "        uf = UnionFind(all_websites)\n",
    "        merges_blocked = 0\n",
    "        \n",
    "        # Process similar pairs with optional color gating\n",
    "        for website1, website2, similarity in similar_pairs:\n",
    "            if website1 in all_websites and website2 in all_websites:\n",
    "                # Check color gate if enabled\n",
    "                if color_gate:\n",
    "                    # Find color vectors for both websites\n",
    "                    logo1_color = None\n",
    "                    logo2_color = None\n",
    "                    \n",
    "                    for logo in valid_logos:\n",
    "                        if logo['website'] == website1:\n",
    "                            logo1_color = logo['features'].get('color_vector')\n",
    "                        elif logo['website'] == website2:\n",
    "                            logo2_color = logo['features'].get('color_vector')\n",
    "                    \n",
    "                    # Check color distance\n",
    "                    if logo1_color and logo2_color:\n",
    "                        color_dist = color_distance(logo1_color, logo2_color)\n",
    "                        if color_dist > color_threshold:\n",
    "                            merges_blocked += 1\n",
    "                            continue  # Skip merge due to color difference\n",
    "                \n",
    "                # Perform union (merge clusters)\n",
    "                uf.union(website1, website2)\n",
    "        \n",
    "        clusters = uf.get_clusters()\n",
    "        multi_clusters = [cluster for cluster in clusters if len(cluster) > 1]\n",
    "        \n",
    "        print(f\" Clustering: {len(multi_clusters)} brand clusters discovered\")\n",
    "        if color_gate and merges_blocked > 0:\n",
    "            print(f\" Color gate blocked {merges_blocked} merges (preserving color distinctions)\")\n",
    "        \n",
    "        # Show top clusters\n",
    "        if multi_clusters:\n",
    "            sorted_clusters = sorted(multi_clusters, key=len, reverse=True)[:5]\n",
    "            print(\" Top brand clusters:\")\n",
    "            for i, cluster in enumerate(sorted_clusters, 1):\n",
    "                sample_domain = cluster[0].replace('https://', '').replace('http://', '').split('/')[0]\n",
    "                brand_name = sample_domain.split('.')[0] if '.' in sample_domain else sample_domain\n",
    "                print(f\"   {i}. {brand_name}: {len(cluster)} similar logos\")\n",
    "    else:\n",
    "        clusters = [[logo['website']] for logo in valid_logos]\n",
    "        multi_clusters = []\n",
    "        print(\"ℹ  No similar pairs found - each logo in separate cluster\")\n",
    "    \n",
    "    # Step 6: Create Enhanced Visualizations\n",
    "    if create_visuals:\n",
    "        print(f\"\\n STEP 6: ENHANCED VISUALIZATION GENERATION\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        viz_pipeline = LogoVisualizationPipeline()\n",
    "        \n",
    "        # Prepare extraction results for visualization\n",
    "        extraction_data = {\n",
    "            'websites': websites,\n",
    "            'logo_results': logo_results,\n",
    "            'successful_logos': successful_logos\n",
    "        }\n",
    "        \n",
    "        # Load results into visualizer\n",
    "        viz_pipeline.load_results_from_memory(\n",
    "            extraction_data,\n",
    "            analyzed_logos, \n",
    "            similar_pairs,\n",
    "            clusters\n",
    "        )\n",
    "        \n",
    "        # Create all visualizations\n",
    "        viz_pipeline.create_all_visualizations()\n",
    "    \n",
    "    # Step 7: Enhanced Summary Report\n",
    "    total_elapsed = time.time() - total_start_time\n",
    "    \n",
    "    print(f\"\\n ENHANCED PIPELINE COMPLETE!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\" ENHANCED RESULTS SUMMARY:\")\n",
    "    print(f\"   • Websites processed: {len(websites)}\")\n",
    "    print(f\"   • Logos extracted: {len(successful_logos)} ({success_rate:.1f}% success)\")\n",
    "    print(f\"   • Valid feature analysis: {len(valid_logos)}\")\n",
    "    print(f\"   • Similar pairs detected: {len(similar_pairs)}\")\n",
    "    print(f\"   • Brand clusters found: {len(multi_clusters)}\")\n",
    "    print(f\"   • Total processing time: {total_elapsed:.1f}s\")\n",
    "    print()\n",
    "    print(\" ENHANCED FEATURES USED:\")\n",
    "    print(\"    Traditional: pHash, FFT, Fourier-Mellin, SIFT, ORB\")\n",
    "    print(\"    2025 Research: Hu/Zernike moments, texture analysis\")\n",
    "    print(\"    Advanced: Color-aware Fourier-Mellin, saliency weighting\")\n",
    "    print(\"    Multi-method: 9 different similarity detection approaches\")\n",
    "    print(\"    Color-aware: Configurable clustering with color gating\")\n",
    "    \n",
    "    if success_rate >= 97:\n",
    "        print(f\"\\n EXCELLENT! {success_rate:.1f}% extraction success rate achieved!\")\n",
    "    elif success_rate >= 90:\n",
    "        print(f\"\\n GOOD! {success_rate:.1f}% extraction success rate\")\n",
    "    else:\n",
    "        print(f\"\\n {success_rate:.1f}% success rate - consider increasing max_tier\")\n",
    "    \n",
    "    return {\n",
    "        'extraction_data': extraction_data,\n",
    "        'analyzed_logos': analyzed_logos,\n",
    "        'valid_logos': valid_logos,\n",
    "        'similar_pairs': similar_pairs,\n",
    "        'clusters': clusters,\n",
    "        'multi_clusters': multi_clusters,\n",
    "        'success_rate': success_rate,\n",
    "        'total_time': total_elapsed,\n",
    "        'features_enhanced': True,\n",
    "        'color_gate_used': color_gate\n",
    "    }\n",
    "\n",
    "print(\" PIPELINE READY!\")\n",
    "print(\" ALL 2025 research features integrated into main pipeline\")\n",
    "print(\" 49-service API pool for maximum extraction success\")\n",
    "print(\" Multi-method similarity detection with advanced features\")\n",
    "print(\" Color-aware clustering with configurable gating\")\n",
    "print()\n",
    "print(\" USAGE:\")\n",
    "print(\"results = await run_enhanced_logo_analysis_pipeline(\")\n",
    "print(\"    sample_size=50,        # Number of websites to process\")\n",
    "print(\"    max_tier=5,           # API tier limit (1-8)\")\n",
    "print(\"    create_visuals=True,  # Generate charts\")\n",
    "print(\"    color_gate=True,      # Enable color-aware clustering\")\n",
    "print(\"    color_threshold=0.20  # Color distance threshold\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline on your parquet file\n",
    "results = await run_enhanced_logo_analysis_pipeline(\n",
    "    sample_size=50,        # Number of websites to process (start small)\n",
    "    max_tier=5,           # Use first 5 API tiers (most reliable)\n",
    "    create_visuals=True,  # Generate visualization plots\n",
    "    enable_color_clustering=True  # Enable color-aware clustering\n",
    ")\n",
    "\n",
    "print(f\" Analysis complete! Found {len(results['clusters'])} logo clusters\")\n",
    "print(f\" Processed {results['total_processed']} websites\")\n",
    "print(f\" Extraction success rate: {results['extraction_success_rate']:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}