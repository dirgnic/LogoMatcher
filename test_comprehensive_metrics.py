#!/usr/bin/env python3

import numpy as np
import cv2
from PIL import Image
import time
import pickle

def test_comprehensive_metrics():
    """Test the enhanced C++ comprehensive similarity metrics system"""
    
    print("ğŸ”¬ TESTING ENHANCED C++ COMPREHENSIVE METRICS")
    print("=" * 60)
    
    try:
        # Import the enhanced C++ module
        import enhanced_fourier_math_cpp as enhanced_cpp
        print("âœ… Enhanced C++ module loaded successfully")
    except ImportError as e:
        print(f"âŒ Failed to import enhanced C++ module: {e}")
        print("ğŸ’¡ You need to build the enhanced module first:")
        print("   cmake -B build_enhanced -S . -f CMakeLists_enhanced.txt")
        print("   cd build_enhanced && make")
        return
    
    # Load test images from our logo dataset
    print("\nğŸ“‹ Loading test logos from cached data...")
    try:
        with open('comprehensive_logo_extraction_fast_results.pkl', 'rb') as f:
            enhanced_data = pickle.load(f)
        
        successful_logos = enhanced_data.get('successful_logos', [])[:10]  # Test with 10 logos
        print(f"âœ… Loaded {len(successful_logos)} test logos")
        
    except Exception as e:
        print(f"âŒ Failed to load logo data: {e}")
        return
    
    # Convert logo data to numpy arrays
    test_images = []
    test_domains = []
    
    for logo_data in successful_logos:
        try:
            # Convert binary logo data to numpy array
            img_array = np.frombuffer(logo_data['logo_data'], dtype=np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)
            
            if img is not None:
                # Resize to standard size
                img_resized = cv2.resize(img, (128, 128))
                test_images.append(img_resized.astype(np.float64))
                test_domains.append(logo_data['domain'])
                
        except Exception as e:
            print(f"âš ï¸  Failed to process {logo_data['domain']}: {e}")
    
    print(f"âœ… Prepared {len(test_images)} images for testing")
    
    if len(test_images) < 2:
        print("âŒ Need at least 2 images for testing")
        return
    
    # Test 1: Individual feature extraction
    print(f"\nğŸ§ª TEST 1: Individual Feature Extraction")
    print("-" * 40)
    
    analyzer = enhanced_cpp.EnhancedFourierAnalyzer(128)
    
    start_time = time.time()
    features = analyzer.extract_all_features(test_images[0])
    extraction_time = time.time() - start_time
    
    print(f"â±ï¸  Feature extraction time: {extraction_time*1000:.2f}ms")
    print(f"âœ… Features extracted successfully:")
    print(f"   ğŸ“± pHash length: {len(features.phash)}")
    print(f"   ğŸŒŠ FFT features: {len(features.fft_features)}")
    print(f"   ğŸ”„ Fourier-Mellin: {len(features.fmt_signature)}")
    print(f"   ğŸ¨ Color FMT: {len(features.color_fmt_features)}")
    print(f"   âœ¨ Saliency FFT: {len(features.saliency_fft_features)}")
    print(f"   ğŸ“ Hu moments: {len(features.hu_moments)}")
    print(f"   â­• Zernike moments: {len(features.zernike_moments)}")
    print(f"   ğŸ” SIFT signature: {len(features.sift_signature)}")
    print(f"   âš¡ ORB signature: {len(features.orb_signature)}")
    print(f"   ğŸ§© Texture features: {len(features.texture_features)}")
    print(f"   ğŸŒˆ Color features: {len(features.color_features)}")
    print(f"   âœ… Valid: {features.valid}")
    
    # Test 2: Pairwise comprehensive similarity
    print(f"\nğŸ§ª TEST 2: Comprehensive Similarity Metrics")
    print("-" * 40)
    
    similarity_computer = enhanced_cpp.EnhancedSimilarityComputer()
    
    # Extract features for two images
    features1 = analyzer.extract_all_features(test_images[0])
    features2 = analyzer.extract_all_features(test_images[1])
    
    start_time = time.time()
    metrics = similarity_computer.compute_comprehensive_similarity(features1, features2)
    similarity_time = time.time() - start_time
    
    print(f"â±ï¸  Similarity computation time: {similarity_time*1000:.2f}ms")
    print(f"ğŸ¯ Comparing: {test_domains[0]} vs {test_domains[1]}")
    print(f"ğŸ“Š COMPREHENSIVE METRICS:")
    print(f"   ğŸ”¥ Calibrated similarity: {metrics.calibrated_similarity:.4f} ({'âœ… Similar' if metrics.calibrated_similar else 'âŒ Different'})")
    print(f"   ğŸ”— Fused hash distance: {metrics.fused_hash_distance:.4f} ({'âœ… Similar' if metrics.fused_hash_similar else 'âŒ Different'})")
    print(f"   ğŸ“ˆ Confidence score: {metrics.confidence_score:.4f}")
    print(f"   ğŸ“± pHash distance: {metrics.phash_distance:.1f} ({'âœ… Similar' if metrics.phash_similar else 'âŒ Different'})")
    print(f"   ğŸŒŠ FFT similarity: {metrics.fft_similarity:.4f} ({'âœ… Similar' if metrics.fft_similar else 'âŒ Different'})")
    print(f"   ğŸ”„ FMT similarity: {metrics.fmt_similarity:.4f} ({'âœ… Similar' if metrics.fmt_similar else 'âŒ Different'})")
    print(f"   ğŸ¨ Color FMT similarity: {metrics.color_fmt_similarity:.4f} ({'âœ… Similar' if metrics.color_fmt_similar else 'âŒ Different'})")
    print(f"   âœ¨ Saliency FFT similarity: {metrics.saliency_fft_similarity:.4f} ({'âœ… Similar' if metrics.saliency_fft_similar else 'âŒ Different'})")
    print(f"   ğŸ“ Hu similarity: {metrics.hu_similarity:.4f} ({'âœ… Similar' if metrics.hu_similar else 'âŒ Different'})")
    print(f"   â­• Zernike similarity: {metrics.zernike_similarity:.4f} ({'âœ… Similar' if metrics.zernike_similar else 'âŒ Different'})")
    print(f"   ğŸ” SIFT similarity: {metrics.sift_similarity:.4f} ({'âœ… Similar' if metrics.sift_similar else 'âŒ Different'})")
    print(f"   âš¡ ORB similarity: {metrics.orb_similarity:.4f} ({'âœ… Similar' if metrics.orb_similar else 'âŒ Different'})")
    print(f"   ğŸŠ OVERALL DECISION: {'âœ… SIMILAR' if metrics.overall_similar else 'âŒ DIFFERENT'}")
    
    # Test 3: Batch analysis
    if len(test_images) >= 5:
        print(f"\nğŸ§ª TEST 3: Batch Comprehensive Analysis")
        print("-" * 40)
        
        pipeline = enhanced_cpp.EnhancedLogoAnalysisPipeline(128)
        
        start_time = time.time()
        results = pipeline.analyze_logo_batch_comprehensive(test_images[:5], 0.7)
        batch_time = time.time() - start_time
        
        print(f"â±ï¸  Batch analysis time: {batch_time*1000:.2f}ms")
        print(f"ğŸ“Š Batch Analysis Results:")
        print(f"   ğŸ–¼ï¸  Valid images: {results.valid_images}/5")
        print(f"   ğŸ“ Similarity matrix shape: {len(results.similarity_matrix)}x{len(results.similarity_matrix[0])}")
        print(f"   ğŸª Clusters found: {len(results.clusters)}")
        print(f"   ğŸ“ˆ Cluster scores: {[f'{score:.3f}' for score in results.cluster_scores[:3]]}")
        print(f"   âš¡ Total analysis time: {results.analysis_time_ms:.2f}ms")
        
        # Show similarity matrix
        print(f"\nğŸ“Š SIMILARITY MATRIX (first 5x5):")
        for i in range(min(5, len(results.similarity_matrix))):
            row_str = "   "
            for j in range(min(5, len(results.similarity_matrix[i]))):
                row_str += f"{results.similarity_matrix[i][j]:.3f} "
            print(row_str)
    
    # Test 4: High-level convenience functions
    print(f"\nğŸ§ª TEST 4: High-Level Convenience Functions")
    print("-" * 40)
    
    # Test the high-level function that matches your Python logic
    start_time = time.time()
    direct_metrics = enhanced_cpp.compute_comprehensive_similarity_metrics(test_images[0], test_images[1])
    direct_time = time.time() - start_time
    
    print(f"â±ï¸  Direct comparison time: {direct_time*1000:.2f}ms")
    print(f"ğŸ¯ Direct metrics match pipeline: {direct_metrics.overall_similar == metrics.overall_similar}")
    
    # Test batch feature extraction
    start_time = time.time()
    batch_features = enhanced_cpp.batch_feature_extraction(test_images[:3])
    batch_feature_time = time.time() - start_time
    
    print(f"â±ï¸  Batch feature extraction: {batch_feature_time*1000:.2f}ms for 3 images")
    print(f"ğŸ“Š All features valid: {all(f.valid for f in batch_features)}")
    
    # Test 5: Performance benchmark
    print(f"\nğŸ§ª TEST 5: Performance Benchmark")
    print("-" * 40)
    
    benchmark_results = enhanced_cpp.benchmark_comprehensive_analysis(test_images[:3], 5)
    
    print(f"ğŸš€ PERFORMANCE RESULTS:")
    print(f"   â±ï¸  Total time: {benchmark_results['total_time_ms']:.2f}ms")
    print(f"   ğŸ”„ Iterations: {benchmark_results['iterations']}")
    print(f"   ğŸ–¼ï¸  Images per iteration: {benchmark_results['images_per_iteration']}")
    print(f"   ğŸ“ˆ Avg time per iteration: {benchmark_results['avg_time_per_iteration_ms']:.2f}ms")
    print(f"   âš¡ Features per second: {benchmark_results['features_per_second']:.1f}")
    
    # Summary
    print(f"\nğŸ‰ COMPREHENSIVE METRICS TEST COMPLETE!")
    print("=" * 60)
    print(f"âœ… All C++ comprehensive similarity metrics working correctly")
    print(f"ğŸ”¥ Ready for integration with your Python logo analysis pipeline")
    print(f"âš¡ High-performance feature extraction and similarity computation")
    print(f"ğŸ“Š Matches your Python metrics structure exactly")

if __name__ == "__main__":
    test_comprehensive_metrics()
